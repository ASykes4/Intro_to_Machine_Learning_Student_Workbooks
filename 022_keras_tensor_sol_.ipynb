{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gGsMHgvKZVRO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_lu_r1ndZVRR"
      },
      "outputs": [],
      "source": [
        "# Helper to plot loss\n",
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "52niBYdKZVRS"
      },
      "source": [
        "# Keras, TensorFlow, and Neural Network Regression\n",
        "\n",
        "As we have seen, neural networks aren't quite as complex as they appear at first, however we still generally don't want to have to build them from scratch very often. The libraries that we will primarily use for creating neural network models are Tensorflow and Keras. Keras and Tensorflow combine to be roughly what sklearn was for the other types of models we've used. \n",
        "\n",
        "### Tensorflow\n",
        "\n",
        "Tensorflow, developed by Google, is one of the most popular libraries for neural networks. \n",
        "\n",
        "### Keras\n",
        "\n",
        "Keras is another package that provides an an API offering an easier to use interface to Tensorflow, allowing us to use it with code that is higher level, avoiding much of the linear math that can make Tensorflow frustrating. Since its introduction Keras has been wrapped in with Tensorflow and the two are normally now blended together as far as we are concerned. \n",
        "\n",
        "### Other Alternatives\n",
        "\n",
        "Keras and Tensorflow are not the only libraries of neural networks, the primary competitor to Tensorflow is PyTorch, which was developed by Facebook. PyTorch does pretty much the same thing as Tensorflow, we won't look at it. While PyTorch is less commonly used than Tensorflow right now, it has picked up steam recently. There's a pretty high likelihood that both Tensorflow and PyTorch will be common for the foreseeable future.\n",
        "\n",
        "### Optimization and Efficiency Notes\n",
        "\n",
        "Neural networks are very computationally expensive, and can take a long time to train. As we move into looking at some larger models in the near future, the processing time on a typical laptop will become prohibitive. We will utilize Google Colab for some of these examples, which will allow us to borrow some GPU processing that is often drastically faster than what we can get on our own machines.\n",
        "\n",
        "If you happen to have a machine with a nVidia GPU, an M1/M2 Mac, or potentially a couple of other GPUs, you can install an optimized version of Tensorflow on your machine that will allow this stuff to use your GPU and be way faster without using Colab. This isn't required, but it is a good idea if your computer is capable. I don't have a GPU, so I don't have a detailed example, but you can google \"install tensorflow GPU/M1 Mac\" or similar for your GPU and there will be some pretty simple step-by-step instructions. If available, this will make a big difference in the speed of your models. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JrKP3wO_ZVRT",
        "outputId": "1ac1822c-99a5-4e98-ea4d-0158aed55c65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>price</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft_living</th>\n",
              "      <th>sqft_lot</th>\n",
              "      <th>floors</th>\n",
              "      <th>waterfront</th>\n",
              "      <th>view</th>\n",
              "      <th>condition</th>\n",
              "      <th>grade</th>\n",
              "      <th>sqft_above</th>\n",
              "      <th>sqft_basement</th>\n",
              "      <th>yr_built</th>\n",
              "      <th>yr_renovated</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>lat</th>\n",
              "      <th>long</th>\n",
              "      <th>sqft_living15</th>\n",
              "      <th>sqft_lot15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21608</th>\n",
              "      <td>360000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1530</td>\n",
              "      <td>1131</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1530</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>98103</td>\n",
              "      <td>47.6993</td>\n",
              "      <td>-122.346</td>\n",
              "      <td>1530</td>\n",
              "      <td>1509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21609</th>\n",
              "      <td>400000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2.50</td>\n",
              "      <td>2310</td>\n",
              "      <td>5813</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>2310</td>\n",
              "      <td>0</td>\n",
              "      <td>2014</td>\n",
              "      <td>0</td>\n",
              "      <td>98146</td>\n",
              "      <td>47.5107</td>\n",
              "      <td>-122.362</td>\n",
              "      <td>1830</td>\n",
              "      <td>7200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21610</th>\n",
              "      <td>402101.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1020</td>\n",
              "      <td>1350</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1020</td>\n",
              "      <td>0</td>\n",
              "      <td>2009</td>\n",
              "      <td>0</td>\n",
              "      <td>98144</td>\n",
              "      <td>47.5944</td>\n",
              "      <td>-122.299</td>\n",
              "      <td>1020</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21611</th>\n",
              "      <td>400000.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2.50</td>\n",
              "      <td>1600</td>\n",
              "      <td>2388</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1600</td>\n",
              "      <td>0</td>\n",
              "      <td>2004</td>\n",
              "      <td>0</td>\n",
              "      <td>98027</td>\n",
              "      <td>47.5345</td>\n",
              "      <td>-122.069</td>\n",
              "      <td>1410</td>\n",
              "      <td>1287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21612</th>\n",
              "      <td>325000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1020</td>\n",
              "      <td>1076</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1020</td>\n",
              "      <td>0</td>\n",
              "      <td>2008</td>\n",
              "      <td>0</td>\n",
              "      <td>98144</td>\n",
              "      <td>47.5941</td>\n",
              "      <td>-122.299</td>\n",
              "      <td>1020</td>\n",
              "      <td>1357</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  \\\n",
              "21608  360000.0         3       2.50         1530      1131     3.0   \n",
              "21609  400000.0         4       2.50         2310      5813     2.0   \n",
              "21610  402101.0         2       0.75         1020      1350     2.0   \n",
              "21611  400000.0         3       2.50         1600      2388     2.0   \n",
              "21612  325000.0         2       0.75         1020      1076     2.0   \n",
              "\n",
              "       waterfront  view  condition  grade  sqft_above  sqft_basement  \\\n",
              "21608           0     0          3      8        1530              0   \n",
              "21609           0     0          3      8        2310              0   \n",
              "21610           0     0          3      7        1020              0   \n",
              "21611           0     0          3      8        1600              0   \n",
              "21612           0     0          3      7        1020              0   \n",
              "\n",
              "       yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
              "21608      2009             0    98103  47.6993 -122.346           1530   \n",
              "21609      2014             0    98146  47.5107 -122.362           1830   \n",
              "21610      2009             0    98144  47.5944 -122.299           1020   \n",
              "21611      2004             0    98027  47.5345 -122.069           1410   \n",
              "21612      2008             0    98144  47.5941 -122.299           1020   \n",
              "\n",
              "       sqft_lot15  \n",
              "21608        1509  \n",
              "21609        7200  \n",
              "21610        2007  \n",
              "21611        1287  \n",
              "21612        1357  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"data/house_data.csv\")\n",
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uLE617U8ZVRV",
        "outputId": "08d0318a-9c52-4e72-b585-ade094db2591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21613 entries, 0 to 21612\n",
            "Data columns (total 19 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   price          21613 non-null  float64\n",
            " 1   bedrooms       21613 non-null  int64  \n",
            " 2   bathrooms      21613 non-null  float64\n",
            " 3   sqft_living    21613 non-null  int64  \n",
            " 4   sqft_lot       21613 non-null  int64  \n",
            " 5   floors         21613 non-null  float64\n",
            " 6   waterfront     21613 non-null  int64  \n",
            " 7   view           21613 non-null  int64  \n",
            " 8   condition      21613 non-null  int64  \n",
            " 9   grade          21613 non-null  int64  \n",
            " 10  sqft_above     21613 non-null  int64  \n",
            " 11  sqft_basement  21613 non-null  int64  \n",
            " 12  yr_built       21613 non-null  int64  \n",
            " 13  yr_renovated   21613 non-null  int64  \n",
            " 14  zipcode        21613 non-null  int64  \n",
            " 15  lat            21613 non-null  float64\n",
            " 16  long           21613 non-null  float64\n",
            " 17  sqft_living15  21613 non-null  int64  \n",
            " 18  sqft_lot15     21613 non-null  int64  \n",
            "dtypes: float64(5), int64(14)\n",
            "memory usage: 3.1 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ThkDxsnGZVRV",
        "outputId": "fef44a1a-6690-4bd7-b618-dd6261194d3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(21613, 18) (21613, 1)\n"
          ]
        }
      ],
      "source": [
        "y = np.array(df[\"price\"]).reshape(-1,1)\n",
        "X = np.array(df.drop(columns={\"price\"}))\n",
        "print(X.shape, y.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DY9JoSCXZVRW"
      },
      "source": [
        "## Create Model\n",
        "\n",
        "Creating a NN model is slightly different from the normal process that we are used to in sklearn. We need to do a little more work to set it up. \n",
        "\n",
        "### Create Model and Add Layers\n",
        "\n",
        "First we need to make a NN model, it comes \"empty\". We will use a sequential model, which is the most simple type but is less configurable (which we don't care about much right now). The limitation of sequential models is that they can only take in one tensor and only output one tensor. The other options here are \"functional\", which allows for the structure of the model to be configured, and \"model subclassing\", which allows you to build almost everything from scratch. These other types are more complex and more flexible, but actually aren't really needed for most applications, and we won't use them. These more complex models are commonly used for scenarios where the data is complex, such as a self driving car - a model needs to output steering as well as velocity. Also for more complex problems such as language or image processing, this flexibility allows for models to be created that are better able to extract the information from the data.\n",
        "\n",
        "#### Layers\n",
        "\n",
        "Next we need to add some layers. We will start simple with only two \"thinking\" layers, and one to do some processing. We can think of the layers roughly like steps of the sklearn pipeline, with data entering at the first layer and predictions flowing out of the final layer. \n",
        "\n",
        "In addition to \"normal\" neural network layers, there are many other types that can do all kinds of other stuff. One example we will use here is the normalization one at the front. This layer does exactly what you'd expect - it normalizes our data so the rest of the network can use it. The normalize layer will also automatically handle the 2D nature of the data that we are used to, so we don't need to worry about that aspect here. Other layers can do everything from regularization to image processing, they are also commonly inhierited for developers to create custom layers targeting specific tasks. We'll use a few of the other ones as we move through some more complex models.\n",
        "\n",
        "![Keras Layers](images/keras_layers.jpg \"Keras Layers\")\n",
        "\n",
        "#### Dense Layers\n",
        "\n",
        "We'll use dense layers here, and they are the main building block in our models. When adding the layer we need to specify a couple of things. One is the input dimensions - we need to tell the network what the shape of the incomming data is. \n",
        "\n",
        "The other argument is the units, which represents the output dimension. When using these Keras dense layers we don't need to specify each layer's input/output like we did when we made it by hand. We specify both, using units and input_dim, for the first layer that takes in the input; for subsequent layers we can just specify the output and Keras will automatically figure the rest out. \n",
        "\n",
        "Note that there is also an input layer that can be added, we can avoid the need for it by using the input_dim or input_shape as shown below. The two examples there do the same thing, since the input is flat - 18 features. If we are dealing with inputs that do not start out as flat, such as in an image, use the input_shape since you can specify all dimensions; we will see an example of this next time with some images. \n",
        "\n",
        "#### Activation Function\n",
        "\n",
        "For each of our layers we need to define which activation function to use. For now we will use the ReLU function, which is probably the most popular. We'll look at other ones later on. Note that we've left the activation function off of the final layer - we are doing regression so we want that raw value. This is the same idea as with linear regression - we don't want the prediction to be transformed through something like the sigmoid, we just want the number.\n",
        "\n",
        "#### Summary\n",
        "\n",
        "After we've constructed the model, the summary command give us, well, a summary. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIquYAGtZVRX"
      },
      "source": [
        "We are dealing with a bunch of numerical inputs here, so we can add a normalization layer at the front end. Like with sklearn, we want to fit the normalization to the training data only. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zWPhKP3wZVRX",
        "outputId": "4c6bc4d8-4a5f-4da7-edd8-7792b597b931"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-11 13:20:47.863542: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizatio  (None, 18)               37        \n",
            " n)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 18)                342       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 19        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 398\n",
            "Trainable params: 361\n",
            "Non-trainable params: 37\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_train))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(Dense(18, input_shape=(18,), activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6AH5AydZVRY"
      },
      "source": [
        "#### Compile Model\n",
        "\n",
        "Once a model is created we need to compile it. The complie step basically builds the layers we specified above and the loss and optimization parameters below together into a usable model object. When compiling the model we are providing it with the things it needs to calculate error:\n",
        "\n",
        "<ul>\n",
        "<li> Loss - we can provide a loss function that we'd like to use. \n",
        "<li> Optimizer - the optimizer is the algorithm that the model will use to perform the gradient descent to find the lowest error. Adam is a very common choice.\n",
        "<li> Learning rate - the learning rate is provided as a parameter of the optimizer. \n",
        "</ul>\n",
        "\n",
        "##### Optimizing Adam\n",
        "\n",
        "The optimizer is the algorithm used to perform the gradient descent and minimize error. For the most part this isn't something we need to be concerned about. The choice of optimizer is much more important if dealing with very large datasets because different optimizers have different levels of efficiency. For our purposes, we can use Adam and be pretty happy. Adam stands for Adaptive Moment Estimation which means basically that it will adjust itself depending on current gradients. It tends to be efficient both in time and memory, so it is very commonly used. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fEya_QckZVRY"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='mean_absolute_error', optimizer=tf.optimizers.Adam(learning_rate=.01))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "n9TUG422ZVRZ"
      },
      "source": [
        "### Fit the Model\n",
        "\n",
        "The fit command does the same thing that we are used to, it trains the model, however there are some differences. The main difference is that batch_size is almost always set in neural networks, while the sklearn models just take all the data at once. \n",
        "\n",
        "What's a batch? Batches are just subsets of the data, so if the batch size is 100 the algorithm will grab 100 rows at a time before making an update to the weights and bias. There are a few reasons this exists:\n",
        "\n",
        "<ul>\n",
        "<li> Memory constraints - it is common with neural networks to deal with datasets that are extremely large. Processing data that can't fit entirely in RAM is very slow (the computer must swap data from the hard drive to RAM as it is needed) compared to data that is in RAM. Cutting the batch size can avoid this issue. \n",
        "<li> Speed - the math involved in the back propagation can sometimes be very computationally intensive. \n",
        "<li> Accuracy - batch size can have an impact on accuracy, though that impact is not very predictable. For the most part finding an optimal batch size will need to be grid-searched. \n",
        "</ul>\n",
        "\n",
        "The fit command also has the epoch paramater, which instructs on how many times to work through ALL of the data. We want to ensure we have enough epochs to find the optimal solution. Training rounds, or epochs, are one of the key tuning factors when using neural networks. Similar to large trees, large neural networks are capable of learning the training data very well, and carry the same risk of overfitting. With neural networks, a common approach to tuning is to allow the model to train, and cut it off when we start overfitting, or when the testing accuracy starts to decrease.\n",
        "\n",
        "#### Plot the Loss\n",
        "\n",
        "One very common visualization we see with neural networks is a plot of both training and validation loss vs number of epochs. Generally we'll see the training loss drop - first sharply as the model initially fits itself, then more slowly as it becomes more fitted. The validation loss will usually somewhat mirror the training loss, except it will often reach a minimum at some point before again increasing. This minimum point is our best model, when the validation loss starts increasing again, that is a sign that the model has become overfitted - customized to the training data, but less and less generalizable to new data. \n",
        "\n",
        "Set the verbosity to 1 in the fit to get a full list of the loss for each epoch to pinpoint the exact \"ideal\" number of epochs. We'll look more at this in a minute. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bDUXMj_pZVRZ",
        "outputId": "6facd69a-6643-4845-da6f-94199649ac5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "130/130 [==============================] - 2s 5ms/step - loss: 541862.2500 - val_loss: 543480.4375\n",
            "Epoch 2/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 541454.3750 - val_loss: 542785.0625\n",
            "Epoch 3/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 540484.6250 - val_loss: 541549.5625\n",
            "Epoch 4/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 539004.0000 - val_loss: 539820.0000\n",
            "Epoch 5/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 537046.1250 - val_loss: 537629.3125\n",
            "Epoch 6/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 534633.5625 - val_loss: 534992.6875\n",
            "Epoch 7/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 531794.2500 - val_loss: 531936.6250\n",
            "Epoch 8/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 528546.4375 - val_loss: 528481.0625\n",
            "Epoch 9/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 524904.0000 - val_loss: 524645.6875\n",
            "Epoch 10/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 520884.2812 - val_loss: 520440.0312\n",
            "Epoch 11/500\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 516503.5312 - val_loss: 515874.1562\n",
            "Epoch 12/500\n",
            "130/130 [==============================] - 1s 9ms/step - loss: 511778.9688 - val_loss: 510972.2812\n",
            "Epoch 13/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 506719.0625 - val_loss: 505744.6250\n",
            "Epoch 14/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 501335.7812 - val_loss: 500194.0312\n",
            "Epoch 15/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 495642.2188 - val_loss: 494330.3125\n",
            "Epoch 16/500\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 489638.9688 - val_loss: 488172.2500\n",
            "Epoch 17/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 483338.6562 - val_loss: 481706.3750\n",
            "Epoch 18/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 476748.7500 - val_loss: 474966.7500\n",
            "Epoch 19/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 469883.2500 - val_loss: 467928.2500\n",
            "Epoch 20/500\n",
            "130/130 [==============================] - 1s 8ms/step - loss: 462746.9688 - val_loss: 460653.3750\n",
            "Epoch 21/500\n",
            "130/130 [==============================] - 2s 14ms/step - loss: 455355.3438 - val_loss: 453125.5000\n",
            "Epoch 22/500\n",
            "130/130 [==============================] - 1s 10ms/step - loss: 447732.8750 - val_loss: 445380.6250\n",
            "Epoch 23/500\n",
            "130/130 [==============================] - 2s 13ms/step - loss: 439889.0625 - val_loss: 437353.4688\n",
            "Epoch 24/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 431816.2812 - val_loss: 429126.0938\n",
            "Epoch 25/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 423543.4062 - val_loss: 420688.8125\n",
            "Epoch 26/500\n",
            "130/130 [==============================] - 1s 7ms/step - loss: 415071.7812 - val_loss: 412089.7188\n",
            "Epoch 27/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 406443.9062 - val_loss: 403343.7812\n",
            "Epoch 28/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 397731.2188 - val_loss: 394507.6562\n",
            "Epoch 29/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 388966.6875 - val_loss: 385614.5938\n",
            "Epoch 30/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 380127.9062 - val_loss: 376640.0312\n",
            "Epoch 31/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 371304.0000 - val_loss: 367722.8750\n",
            "Epoch 32/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 362567.9375 - val_loss: 359078.5312\n",
            "Epoch 33/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 353960.3125 - val_loss: 350661.3438\n",
            "Epoch 34/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 345561.7812 - val_loss: 342668.7812\n",
            "Epoch 35/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 337485.1875 - val_loss: 335070.0938\n",
            "Epoch 36/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 329775.0938 - val_loss: 327877.2188\n",
            "Epoch 37/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 322450.8125 - val_loss: 321060.5938\n",
            "Epoch 38/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 315477.9062 - val_loss: 314560.0625\n",
            "Epoch 39/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 308860.6562 - val_loss: 308352.9375\n",
            "Epoch 40/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 302597.9375 - val_loss: 302385.5000\n",
            "Epoch 41/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 296660.5625 - val_loss: 296783.4062\n",
            "Epoch 42/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 291020.3438 - val_loss: 291451.5938\n",
            "Epoch 43/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 285574.2500 - val_loss: 286398.0938\n",
            "Epoch 44/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 280456.5938 - val_loss: 281563.5625\n",
            "Epoch 45/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 275688.3750 - val_loss: 277218.5938\n",
            "Epoch 46/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 271326.3438 - val_loss: 273200.8125\n",
            "Epoch 47/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 267339.8750 - val_loss: 269512.3438\n",
            "Epoch 48/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 263736.9688 - val_loss: 266116.9062\n",
            "Epoch 49/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 260494.5781 - val_loss: 262990.4062\n",
            "Epoch 50/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 257524.6719 - val_loss: 260075.5625\n",
            "Epoch 51/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 254779.9844 - val_loss: 257384.9219\n",
            "Epoch 52/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 252239.8438 - val_loss: 254847.4531\n",
            "Epoch 53/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 249830.3594 - val_loss: 252449.3281\n",
            "Epoch 54/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 247529.0000 - val_loss: 250158.8594\n",
            "Epoch 55/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 245324.7344 - val_loss: 247973.6875\n",
            "Epoch 56/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 243205.9219 - val_loss: 245889.7969\n",
            "Epoch 57/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 241178.9531 - val_loss: 243857.5312\n",
            "Epoch 58/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 239216.4688 - val_loss: 241856.2969\n",
            "Epoch 59/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 237304.9531 - val_loss: 239880.8281\n",
            "Epoch 60/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 235433.7812 - val_loss: 237953.4844\n",
            "Epoch 61/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 233600.5469 - val_loss: 236060.2656\n",
            "Epoch 62/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 231796.6250 - val_loss: 234214.9844\n",
            "Epoch 63/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 230026.3906 - val_loss: 232393.3438\n",
            "Epoch 64/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 228280.8906 - val_loss: 230602.4688\n",
            "Epoch 65/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 226561.9219 - val_loss: 228821.2031\n",
            "Epoch 66/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 224879.2500 - val_loss: 227087.8125\n",
            "Epoch 67/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 223216.1094 - val_loss: 225377.8281\n",
            "Epoch 68/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 221571.1719 - val_loss: 223659.9062\n",
            "Epoch 69/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 219925.6250 - val_loss: 221938.1094\n",
            "Epoch 70/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 218277.6719 - val_loss: 220196.0000\n",
            "Epoch 71/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 216618.2344 - val_loss: 218470.7344\n",
            "Epoch 72/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 214965.9531 - val_loss: 216758.3438\n",
            "Epoch 73/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 213320.1562 - val_loss: 215052.9688\n",
            "Epoch 74/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 211670.2656 - val_loss: 213367.6250\n",
            "Epoch 75/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 210038.6562 - val_loss: 211687.8594\n",
            "Epoch 76/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 208429.0312 - val_loss: 210027.5469\n",
            "Epoch 77/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 206837.4844 - val_loss: 208426.7969\n",
            "Epoch 78/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 205275.0000 - val_loss: 206832.5469\n",
            "Epoch 79/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 203731.4219 - val_loss: 205259.3906\n",
            "Epoch 80/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 202208.4688 - val_loss: 203739.2500\n",
            "Epoch 81/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 200726.0938 - val_loss: 202245.7969\n",
            "Epoch 82/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 199264.8750 - val_loss: 200751.2344\n",
            "Epoch 83/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 197818.5000 - val_loss: 199284.5469\n",
            "Epoch 84/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 196393.8594 - val_loss: 197834.3594\n",
            "Epoch 85/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 194999.2031 - val_loss: 196423.7031\n",
            "Epoch 86/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 193634.0625 - val_loss: 195054.9688\n",
            "Epoch 87/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 192297.4531 - val_loss: 193713.4844\n",
            "Epoch 88/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 191004.6406 - val_loss: 192393.2812\n",
            "Epoch 89/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 189748.9531 - val_loss: 191114.3281\n",
            "Epoch 90/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 188529.4844 - val_loss: 189872.5781\n",
            "Epoch 91/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 187332.3906 - val_loss: 188671.1094\n",
            "Epoch 92/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 186167.7344 - val_loss: 187499.8906\n",
            "Epoch 93/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 185035.1250 - val_loss: 186351.3438\n",
            "Epoch 94/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 183926.9688 - val_loss: 185223.5000\n",
            "Epoch 95/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 182837.2188 - val_loss: 184101.8281\n",
            "Epoch 96/500\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 181775.8750 - val_loss: 183010.0312\n",
            "Epoch 97/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 180732.7031 - val_loss: 181941.4844\n",
            "Epoch 98/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 179716.7188 - val_loss: 180892.3906\n",
            "Epoch 99/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 178716.7969 - val_loss: 179876.1406\n",
            "Epoch 100/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 177727.9688 - val_loss: 178893.9375\n",
            "Epoch 101/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 176749.0938 - val_loss: 177911.8125\n",
            "Epoch 102/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 175774.3281 - val_loss: 176933.2656\n",
            "Epoch 103/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 174825.3125 - val_loss: 175997.9062\n",
            "Epoch 104/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 173893.4375 - val_loss: 175060.6250\n",
            "Epoch 105/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 172973.6094 - val_loss: 174128.2031\n",
            "Epoch 106/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 172060.4688 - val_loss: 173217.2969\n",
            "Epoch 107/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 171163.0156 - val_loss: 172311.8125\n",
            "Epoch 108/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 170285.7812 - val_loss: 171424.9531\n",
            "Epoch 109/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 169415.5625 - val_loss: 170546.0000\n",
            "Epoch 110/500\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 168559.1250 - val_loss: 169686.3281\n",
            "Epoch 111/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 167709.8281 - val_loss: 168843.1562\n",
            "Epoch 112/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 166877.5469 - val_loss: 168025.2812\n",
            "Epoch 113/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 166051.5781 - val_loss: 167223.0781\n",
            "Epoch 114/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 165229.1719 - val_loss: 166433.4062\n",
            "Epoch 115/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 164413.6875 - val_loss: 165655.2031\n",
            "Epoch 116/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 163614.7344 - val_loss: 164892.3750\n",
            "Epoch 117/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 162832.8750 - val_loss: 164145.4844\n",
            "Epoch 118/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 162049.7656 - val_loss: 163391.7500\n",
            "Epoch 119/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 161265.2500 - val_loss: 162641.5625\n",
            "Epoch 120/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 160488.1719 - val_loss: 161904.7969\n",
            "Epoch 121/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 159718.1719 - val_loss: 161177.0781\n",
            "Epoch 122/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 158952.1562 - val_loss: 160449.6875\n",
            "Epoch 123/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 158192.9375 - val_loss: 159727.2969\n",
            "Epoch 124/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 157432.0781 - val_loss: 158997.5000\n",
            "Epoch 125/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 156673.9844 - val_loss: 158275.2969\n",
            "Epoch 126/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 155911.0625 - val_loss: 157576.7500\n",
            "Epoch 127/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 155165.5625 - val_loss: 156864.9688\n",
            "Epoch 128/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 154418.7188 - val_loss: 156146.0781\n",
            "Epoch 129/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 153664.7969 - val_loss: 155436.8594\n",
            "Epoch 130/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 152914.1250 - val_loss: 154720.4375\n",
            "Epoch 131/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 152158.8125 - val_loss: 154021.8594\n",
            "Epoch 132/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 151403.2344 - val_loss: 153306.8125\n",
            "Epoch 133/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 150647.5625 - val_loss: 152592.5625\n",
            "Epoch 134/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 149901.6250 - val_loss: 151890.4844\n",
            "Epoch 135/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 149158.1875 - val_loss: 151176.9375\n",
            "Epoch 136/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 148408.1406 - val_loss: 150465.3906\n",
            "Epoch 137/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 147665.9375 - val_loss: 149741.1719\n",
            "Epoch 138/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 146927.3438 - val_loss: 149039.0469\n",
            "Epoch 139/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 146179.3438 - val_loss: 148332.8750\n",
            "Epoch 140/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 145433.4219 - val_loss: 147631.1406\n",
            "Epoch 141/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 144689.6875 - val_loss: 146931.6094\n",
            "Epoch 142/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 143937.8750 - val_loss: 146242.5625\n",
            "Epoch 143/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 143186.1406 - val_loss: 145541.2188\n",
            "Epoch 144/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 142433.2969 - val_loss: 144851.1562\n",
            "Epoch 145/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 141671.8750 - val_loss: 144156.9062\n",
            "Epoch 146/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 140925.2031 - val_loss: 143466.0312\n",
            "Epoch 147/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 140184.2812 - val_loss: 142792.7812\n",
            "Epoch 148/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 139438.9219 - val_loss: 142103.8594\n",
            "Epoch 149/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 138698.8906 - val_loss: 141431.4844\n",
            "Epoch 150/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 137962.6406 - val_loss: 140751.3906\n",
            "Epoch 151/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 137238.3125 - val_loss: 140074.7031\n",
            "Epoch 152/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 136514.9375 - val_loss: 139401.6250\n",
            "Epoch 153/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 135797.1562 - val_loss: 138739.0625\n",
            "Epoch 154/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 135090.1250 - val_loss: 138077.0938\n",
            "Epoch 155/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 134389.1875 - val_loss: 137431.9844\n",
            "Epoch 156/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 133700.6875 - val_loss: 136780.9375\n",
            "Epoch 157/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 133024.1562 - val_loss: 136140.6094\n",
            "Epoch 158/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 132367.7500 - val_loss: 135516.0625\n",
            "Epoch 159/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 131712.1875 - val_loss: 134891.8125\n",
            "Epoch 160/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 131070.4766 - val_loss: 134275.5781\n",
            "Epoch 161/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 130434.6172 - val_loss: 133674.4688\n",
            "Epoch 162/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 129815.4453 - val_loss: 133086.4062\n",
            "Epoch 163/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 129200.8438 - val_loss: 132497.7969\n",
            "Epoch 164/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 128598.4219 - val_loss: 131927.6875\n",
            "Epoch 165/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 128009.1484 - val_loss: 131358.8125\n",
            "Epoch 166/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 127439.6094 - val_loss: 130815.6953\n",
            "Epoch 167/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 126872.9531 - val_loss: 130292.3438\n",
            "Epoch 168/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 126325.2578 - val_loss: 129756.4766\n",
            "Epoch 169/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 125788.1484 - val_loss: 129259.6562\n",
            "Epoch 170/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 125265.7031 - val_loss: 128761.3281\n",
            "Epoch 171/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 124755.9062 - val_loss: 128274.3672\n",
            "Epoch 172/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 124260.7812 - val_loss: 127799.0469\n",
            "Epoch 173/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 123769.7500 - val_loss: 127319.4453\n",
            "Epoch 174/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 123289.5781 - val_loss: 126862.7656\n",
            "Epoch 175/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 122818.5781 - val_loss: 126422.7188\n",
            "Epoch 176/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 122371.6953 - val_loss: 125990.1484\n",
            "Epoch 177/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 121922.6094 - val_loss: 125563.6094\n",
            "Epoch 178/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 121493.9922 - val_loss: 125160.5938\n",
            "Epoch 179/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 121076.8281 - val_loss: 124768.5156\n",
            "Epoch 180/500\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 120670.6250 - val_loss: 124378.5938\n",
            "Epoch 181/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 120269.2812 - val_loss: 123999.9375\n",
            "Epoch 182/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 119884.2031 - val_loss: 123648.5625\n",
            "Epoch 183/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 119504.7578 - val_loss: 123295.7891\n",
            "Epoch 184/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 119132.7500 - val_loss: 122962.7969\n",
            "Epoch 185/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 118771.2656 - val_loss: 122640.9297\n",
            "Epoch 186/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 118418.4375 - val_loss: 122324.2578\n",
            "Epoch 187/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 118077.6172 - val_loss: 122033.5625\n",
            "Epoch 188/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 117754.1641 - val_loss: 121760.7266\n",
            "Epoch 189/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 117448.7891 - val_loss: 121496.7422\n",
            "Epoch 190/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 117146.0859 - val_loss: 121230.8359\n",
            "Epoch 191/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 116863.6328 - val_loss: 120980.3906\n",
            "Epoch 192/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 116588.9609 - val_loss: 120733.5625\n",
            "Epoch 193/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 116329.6094 - val_loss: 120508.5938\n",
            "Epoch 194/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 116083.5703 - val_loss: 120293.9062\n",
            "Epoch 195/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 115842.2500 - val_loss: 120087.0781\n",
            "Epoch 196/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 115612.1250 - val_loss: 119886.2656\n",
            "Epoch 197/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 115389.3984 - val_loss: 119697.7656\n",
            "Epoch 198/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 115170.9297 - val_loss: 119509.9688\n",
            "Epoch 199/500\n",
            "130/130 [==============================] - 0s 1ms/step - loss: 114961.2812 - val_loss: 119346.9922\n",
            "Epoch 200/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 114765.7031 - val_loss: 119183.8594\n",
            "Epoch 201/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 114577.9453 - val_loss: 119024.3438\n",
            "Epoch 202/500\n",
            "130/130 [==============================] - 0s 1ms/step - loss: 114399.9844 - val_loss: 118891.2422\n",
            "Epoch 203/500\n",
            "130/130 [==============================] - 0s 1ms/step - loss: 114225.1797 - val_loss: 118760.2188\n",
            "Epoch 204/500\n",
            "130/130 [==============================] - 0s 1ms/step - loss: 114055.4219 - val_loss: 118626.2500\n",
            "Epoch 205/500\n",
            "130/130 [==============================] - 0s 1ms/step - loss: 113895.1875 - val_loss: 118499.4609\n",
            "Epoch 206/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 113739.5625 - val_loss: 118388.8594\n",
            "Epoch 207/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 113597.3281 - val_loss: 118275.0781\n",
            "Epoch 208/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 113455.6562 - val_loss: 118170.1250\n",
            "Epoch 209/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 113321.1406 - val_loss: 118071.4141\n",
            "Epoch 210/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 113194.1562 - val_loss: 117978.9922\n",
            "Epoch 211/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 113075.5312 - val_loss: 117884.6797\n",
            "Epoch 212/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 112958.8828 - val_loss: 117799.1562\n",
            "Epoch 213/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 112850.3984 - val_loss: 117712.8672\n",
            "Epoch 214/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 112748.4141 - val_loss: 117618.9922\n",
            "Epoch 215/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 112650.7891 - val_loss: 117542.4688\n",
            "Epoch 216/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 112560.0625 - val_loss: 117464.9844\n",
            "Epoch 217/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 112466.6406 - val_loss: 117397.9609\n",
            "Epoch 218/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 112381.8281 - val_loss: 117325.5234\n",
            "Epoch 219/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 112302.3750 - val_loss: 117262.4688\n",
            "Epoch 220/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 112228.4922 - val_loss: 117198.2109\n",
            "Epoch 221/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 112150.3750 - val_loss: 117135.9609\n",
            "Epoch 222/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 112087.5469 - val_loss: 117077.5391\n",
            "Epoch 223/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 112016.1016 - val_loss: 117015.8438\n",
            "Epoch 224/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111952.3438 - val_loss: 116968.5938\n",
            "Epoch 225/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111885.7031 - val_loss: 116909.2031\n",
            "Epoch 226/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111829.2969 - val_loss: 116850.2812\n",
            "Epoch 227/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111768.2422 - val_loss: 116798.5156\n",
            "Epoch 228/500\n",
            "130/130 [==============================] - 0s 1ms/step - loss: 111717.5234 - val_loss: 116749.2344\n",
            "Epoch 229/500\n",
            "130/130 [==============================] - 0s 1ms/step - loss: 111661.2422 - val_loss: 116702.7734\n",
            "Epoch 230/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 111603.3047 - val_loss: 116656.2734\n",
            "Epoch 231/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 111550.5156 - val_loss: 116608.3438\n",
            "Epoch 232/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 111505.6953 - val_loss: 116569.1094\n",
            "Epoch 233/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111452.0312 - val_loss: 116515.1094\n",
            "Epoch 234/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111399.7969 - val_loss: 116469.0469\n",
            "Epoch 235/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111355.2109 - val_loss: 116421.4453\n",
            "Epoch 236/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111308.6484 - val_loss: 116375.9766\n",
            "Epoch 237/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111262.3125 - val_loss: 116326.7188\n",
            "Epoch 238/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111218.9609 - val_loss: 116288.5234\n",
            "Epoch 239/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111176.9609 - val_loss: 116242.5234\n",
            "Epoch 240/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111133.5312 - val_loss: 116203.0078\n",
            "Epoch 241/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111091.3359 - val_loss: 116163.7031\n",
            "Epoch 242/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 111050.1953 - val_loss: 116122.2578\n",
            "Epoch 243/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 111013.0469 - val_loss: 116083.6953\n",
            "Epoch 244/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110972.4766 - val_loss: 116046.8438\n",
            "Epoch 245/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110934.5391 - val_loss: 116012.5547\n",
            "Epoch 246/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110895.3906 - val_loss: 115970.4219\n",
            "Epoch 247/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110857.8516 - val_loss: 115936.0078\n",
            "Epoch 248/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 110823.9453 - val_loss: 115900.2891\n",
            "Epoch 249/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 110787.0391 - val_loss: 115866.7891\n",
            "Epoch 250/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 110752.3203 - val_loss: 115834.7891\n",
            "Epoch 251/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110720.4531 - val_loss: 115802.3672\n",
            "Epoch 252/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110688.9453 - val_loss: 115773.8359\n",
            "Epoch 253/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 110651.2188 - val_loss: 115734.4141\n",
            "Epoch 254/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 110618.1484 - val_loss: 115711.8906\n",
            "Epoch 255/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 110584.9141 - val_loss: 115681.9922\n",
            "Epoch 256/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 110558.7031 - val_loss: 115637.9141\n",
            "Epoch 257/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110525.6719 - val_loss: 115616.7422\n",
            "Epoch 258/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 110491.8672 - val_loss: 115581.8750\n",
            "Epoch 259/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110461.8359 - val_loss: 115554.9219\n",
            "Epoch 260/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110431.1484 - val_loss: 115524.2266\n",
            "Epoch 261/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 110400.3594 - val_loss: 115488.5859\n",
            "Epoch 262/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 110370.6797 - val_loss: 115457.9219\n",
            "Epoch 263/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 110338.7969 - val_loss: 115427.6328\n",
            "Epoch 264/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110311.7188 - val_loss: 115394.1641\n",
            "Epoch 265/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 110280.8906 - val_loss: 115366.9766\n",
            "Epoch 266/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 110257.0469 - val_loss: 115334.4375\n",
            "Epoch 267/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110224.1172 - val_loss: 115305.5938\n",
            "Epoch 268/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110196.7578 - val_loss: 115274.5391\n",
            "Epoch 269/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 110170.1562 - val_loss: 115237.9297\n",
            "Epoch 270/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110142.6016 - val_loss: 115211.4141\n",
            "Epoch 271/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 110114.2891 - val_loss: 115183.6172\n",
            "Epoch 272/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110087.9766 - val_loss: 115158.4922\n",
            "Epoch 273/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110062.9531 - val_loss: 115134.4219\n",
            "Epoch 274/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110036.1641 - val_loss: 115099.5781\n",
            "Epoch 275/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 110008.0859 - val_loss: 115070.7266\n",
            "Epoch 276/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 109985.0156 - val_loss: 115044.7188\n",
            "Epoch 277/500\n",
            "130/130 [==============================] - 2s 13ms/step - loss: 109960.4766 - val_loss: 115019.3047\n",
            "Epoch 278/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 109938.7422 - val_loss: 114988.5078\n",
            "Epoch 279/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 109907.2812 - val_loss: 114969.1016\n",
            "Epoch 280/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 109885.2578 - val_loss: 114943.3906\n",
            "Epoch 281/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 109857.5781 - val_loss: 114919.0859\n",
            "Epoch 282/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109833.8047 - val_loss: 114884.7969\n",
            "Epoch 283/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 109808.0703 - val_loss: 114862.7969\n",
            "Epoch 284/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109787.2812 - val_loss: 114840.8438\n",
            "Epoch 285/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109758.5156 - val_loss: 114812.0547\n",
            "Epoch 286/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109737.8906 - val_loss: 114786.3359\n",
            "Epoch 287/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109713.9141 - val_loss: 114761.3594\n",
            "Epoch 288/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109691.0469 - val_loss: 114734.3594\n",
            "Epoch 289/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109666.7109 - val_loss: 114709.5391\n",
            "Epoch 290/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 109640.5703 - val_loss: 114691.7109\n",
            "Epoch 291/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 109623.4766 - val_loss: 114649.6797\n",
            "Epoch 292/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109599.9844 - val_loss: 114632.1328\n",
            "Epoch 293/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 109572.6172 - val_loss: 114603.4375\n",
            "Epoch 294/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 109551.0703 - val_loss: 114581.1406\n",
            "Epoch 295/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109530.0469 - val_loss: 114555.5859\n",
            "Epoch 296/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 109509.6719 - val_loss: 114526.1328\n",
            "Epoch 297/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 109486.2656 - val_loss: 114505.1797\n",
            "Epoch 298/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 109464.5469 - val_loss: 114482.5859\n",
            "Epoch 299/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 109443.5078 - val_loss: 114453.6562\n",
            "Epoch 300/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109420.9453 - val_loss: 114432.1250\n",
            "Epoch 301/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109398.7266 - val_loss: 114404.9766\n",
            "Epoch 302/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109378.2734 - val_loss: 114380.9297\n",
            "Epoch 303/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 109355.0000 - val_loss: 114360.0859\n",
            "Epoch 304/500\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 109336.9531 - val_loss: 114336.0312\n",
            "Epoch 305/500\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 109316.9375 - val_loss: 114314.1641\n",
            "Epoch 306/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109296.1406 - val_loss: 114286.8672\n",
            "Epoch 307/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109274.9062 - val_loss: 114269.3750\n",
            "Epoch 308/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109250.6172 - val_loss: 114242.4219\n",
            "Epoch 309/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109229.5625 - val_loss: 114213.8828\n",
            "Epoch 310/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 109211.2656 - val_loss: 114196.1875\n",
            "Epoch 311/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 109191.2969 - val_loss: 114171.1719\n",
            "Epoch 312/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 109170.0938 - val_loss: 114151.3828\n",
            "Epoch 313/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 109151.1562 - val_loss: 114122.1250\n",
            "Epoch 314/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109129.8750 - val_loss: 114092.2266\n",
            "Epoch 315/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109114.9141 - val_loss: 114071.5938\n",
            "Epoch 316/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 109097.3906 - val_loss: 114050.3984\n",
            "Epoch 317/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 109069.8516 - val_loss: 114027.5312\n",
            "Epoch 318/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 109050.0469 - val_loss: 114005.3672\n",
            "Epoch 319/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 109029.9922 - val_loss: 113981.9375\n",
            "Epoch 320/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 109010.0781 - val_loss: 113955.9219\n",
            "Epoch 321/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108992.4922 - val_loss: 113927.1797\n",
            "Epoch 322/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108974.6797 - val_loss: 113903.2500\n",
            "Epoch 323/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108958.4141 - val_loss: 113885.7266\n",
            "Epoch 324/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108933.9609 - val_loss: 113864.8047\n",
            "Epoch 325/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 108914.3594 - val_loss: 113839.1016\n",
            "Epoch 326/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108893.9531 - val_loss: 113809.9219\n",
            "Epoch 327/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108876.2031 - val_loss: 113793.8125\n",
            "Epoch 328/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108855.8906 - val_loss: 113772.1484\n",
            "Epoch 329/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108836.9062 - val_loss: 113747.2500\n",
            "Epoch 330/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108816.6328 - val_loss: 113725.4375\n",
            "Epoch 331/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 108797.9375 - val_loss: 113705.0625\n",
            "Epoch 332/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108778.9375 - val_loss: 113680.2578\n",
            "Epoch 333/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108760.5312 - val_loss: 113663.1250\n",
            "Epoch 334/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108738.3047 - val_loss: 113645.6016\n",
            "Epoch 335/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108723.6172 - val_loss: 113623.7656\n",
            "Epoch 336/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 108700.7656 - val_loss: 113595.5469\n",
            "Epoch 337/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 108682.5312 - val_loss: 113571.7109\n",
            "Epoch 338/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108663.4219 - val_loss: 113546.8359\n",
            "Epoch 339/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108642.7812 - val_loss: 113527.8047\n",
            "Epoch 340/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108625.7031 - val_loss: 113503.8203\n",
            "Epoch 341/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108605.5859 - val_loss: 113473.0391\n",
            "Epoch 342/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108587.6484 - val_loss: 113460.4609\n",
            "Epoch 343/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108567.9844 - val_loss: 113439.9375\n",
            "Epoch 344/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108553.7031 - val_loss: 113412.0234\n",
            "Epoch 345/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 108529.6797 - val_loss: 113392.6875\n",
            "Epoch 346/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108513.1641 - val_loss: 113372.0391\n",
            "Epoch 347/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108492.7188 - val_loss: 113356.1406\n",
            "Epoch 348/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108475.0469 - val_loss: 113338.3516\n",
            "Epoch 349/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108455.7031 - val_loss: 113314.6875\n",
            "Epoch 350/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108435.2578 - val_loss: 113296.8203\n",
            "Epoch 351/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 108422.7500 - val_loss: 113271.3125\n",
            "Epoch 352/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108402.2656 - val_loss: 113253.8203\n",
            "Epoch 353/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 108380.2344 - val_loss: 113228.2422\n",
            "Epoch 354/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108366.6016 - val_loss: 113211.2266\n",
            "Epoch 355/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108344.1875 - val_loss: 113192.9688\n",
            "Epoch 356/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108326.9922 - val_loss: 113167.0234\n",
            "Epoch 357/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 108314.7812 - val_loss: 113150.4531\n",
            "Epoch 358/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108294.3281 - val_loss: 113131.0859\n",
            "Epoch 359/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108276.7578 - val_loss: 113106.2891\n",
            "Epoch 360/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108252.8906 - val_loss: 113085.5938\n",
            "Epoch 361/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108236.7422 - val_loss: 113061.6094\n",
            "Epoch 362/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108222.6953 - val_loss: 113048.9453\n",
            "Epoch 363/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108208.1250 - val_loss: 113029.3594\n",
            "Epoch 364/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 108185.8828 - val_loss: 112995.9609\n",
            "Epoch 365/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108167.5312 - val_loss: 112985.4375\n",
            "Epoch 366/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108149.6094 - val_loss: 112955.6641\n",
            "Epoch 367/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108130.3359 - val_loss: 112940.3047\n",
            "Epoch 368/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108113.5469 - val_loss: 112927.4297\n",
            "Epoch 369/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108095.7188 - val_loss: 112897.8438\n",
            "Epoch 370/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108076.9531 - val_loss: 112883.2109\n",
            "Epoch 371/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 108061.2109 - val_loss: 112861.3359\n",
            "Epoch 372/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 108044.3672 - val_loss: 112837.8203\n",
            "Epoch 373/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108031.5859 - val_loss: 112812.2031\n",
            "Epoch 374/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 108008.5234 - val_loss: 112799.3672\n",
            "Epoch 375/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107992.7109 - val_loss: 112783.3203\n",
            "Epoch 376/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107975.0312 - val_loss: 112753.6172\n",
            "Epoch 377/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107954.6562 - val_loss: 112739.3828\n",
            "Epoch 378/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 107935.2109 - val_loss: 112718.8750\n",
            "Epoch 379/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107922.5859 - val_loss: 112695.9297\n",
            "Epoch 380/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 107906.0547 - val_loss: 112676.7188\n",
            "Epoch 381/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107885.1094 - val_loss: 112656.0078\n",
            "Epoch 382/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107868.8125 - val_loss: 112638.2891\n",
            "Epoch 383/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107850.2031 - val_loss: 112621.4375\n",
            "Epoch 384/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107831.7422 - val_loss: 112599.4844\n",
            "Epoch 385/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 107813.6875 - val_loss: 112578.5078\n",
            "Epoch 386/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107797.2344 - val_loss: 112564.4922\n",
            "Epoch 387/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107779.4609 - val_loss: 112541.9766\n",
            "Epoch 388/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107762.4844 - val_loss: 112530.1094\n",
            "Epoch 389/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107746.9453 - val_loss: 112507.8516\n",
            "Epoch 390/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107731.2031 - val_loss: 112482.2734\n",
            "Epoch 391/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107707.0859 - val_loss: 112461.8906\n",
            "Epoch 392/500\n",
            "130/130 [==============================] - 1s 6ms/step - loss: 107693.8359 - val_loss: 112451.8359\n",
            "Epoch 393/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107675.7656 - val_loss: 112429.7266\n",
            "Epoch 394/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107658.2969 - val_loss: 112412.8594\n",
            "Epoch 395/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 107636.5078 - val_loss: 112384.0000\n",
            "Epoch 396/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107619.6328 - val_loss: 112372.2344\n",
            "Epoch 397/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107604.1016 - val_loss: 112345.2500\n",
            "Epoch 398/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 107587.7969 - val_loss: 112332.7734\n",
            "Epoch 399/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107569.8125 - val_loss: 112311.6797\n",
            "Epoch 400/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107552.2422 - val_loss: 112294.9453\n",
            "Epoch 401/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107534.6484 - val_loss: 112278.1172\n",
            "Epoch 402/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107512.0859 - val_loss: 112249.3906\n",
            "Epoch 403/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107499.4453 - val_loss: 112227.3594\n",
            "Epoch 404/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 107483.7500 - val_loss: 112212.6562\n",
            "Epoch 405/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107462.5312 - val_loss: 112188.2031\n",
            "Epoch 406/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107443.6094 - val_loss: 112177.5312\n",
            "Epoch 407/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107427.8047 - val_loss: 112167.1484\n",
            "Epoch 408/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 107413.7031 - val_loss: 112141.7656\n",
            "Epoch 409/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107394.1953 - val_loss: 112125.2266\n",
            "Epoch 410/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 107380.5859 - val_loss: 112105.6328\n",
            "Epoch 411/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107356.2891 - val_loss: 112082.2734\n",
            "Epoch 412/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107342.9219 - val_loss: 112076.3281\n",
            "Epoch 413/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107326.0000 - val_loss: 112045.2656\n",
            "Epoch 414/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107309.2266 - val_loss: 112032.1406\n",
            "Epoch 415/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107293.9531 - val_loss: 112011.8516\n",
            "Epoch 416/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107272.6875 - val_loss: 112000.9766\n",
            "Epoch 417/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 107253.6250 - val_loss: 111976.6953\n",
            "Epoch 418/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 107239.0781 - val_loss: 111944.0938\n",
            "Epoch 419/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107221.7031 - val_loss: 111937.4375\n",
            "Epoch 420/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107203.8516 - val_loss: 111911.4844\n",
            "Epoch 421/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 107184.8828 - val_loss: 111899.9531\n",
            "Epoch 422/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107170.6875 - val_loss: 111888.2109\n",
            "Epoch 423/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107153.4062 - val_loss: 111865.8125\n",
            "Epoch 424/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107130.9453 - val_loss: 111842.9922\n",
            "Epoch 425/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107116.0234 - val_loss: 111828.6094\n",
            "Epoch 426/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107098.8828 - val_loss: 111809.6094\n",
            "Epoch 427/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107080.7188 - val_loss: 111780.0547\n",
            "Epoch 428/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107063.5625 - val_loss: 111767.5625\n",
            "Epoch 429/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 107047.2578 - val_loss: 111755.4531\n",
            "Epoch 430/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 107025.8281 - val_loss: 111729.7188\n",
            "Epoch 431/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 107009.2031 - val_loss: 111712.6016\n",
            "Epoch 432/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106992.5391 - val_loss: 111695.6953\n",
            "Epoch 433/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106974.2188 - val_loss: 111670.4844\n",
            "Epoch 434/500\n",
            "130/130 [==============================] - 1s 9ms/step - loss: 106958.9922 - val_loss: 111655.0703\n",
            "Epoch 435/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106939.0625 - val_loss: 111638.6016\n",
            "Epoch 436/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 106925.0156 - val_loss: 111610.2812\n",
            "Epoch 437/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106909.8203 - val_loss: 111597.0078\n",
            "Epoch 438/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 106891.3594 - val_loss: 111582.2344\n",
            "Epoch 439/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106871.7500 - val_loss: 111549.3672\n",
            "Epoch 440/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106852.5703 - val_loss: 111544.6250\n",
            "Epoch 441/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106838.7891 - val_loss: 111514.5781\n",
            "Epoch 442/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 106823.1797 - val_loss: 111496.6250\n",
            "Epoch 443/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106798.6094 - val_loss: 111475.3750\n",
            "Epoch 444/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 106785.2969 - val_loss: 111454.6797\n",
            "Epoch 445/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 106764.7500 - val_loss: 111438.6953\n",
            "Epoch 446/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106750.1406 - val_loss: 111414.1406\n",
            "Epoch 447/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106729.7500 - val_loss: 111386.9766\n",
            "Epoch 448/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106715.4375 - val_loss: 111374.5469\n",
            "Epoch 449/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106693.1641 - val_loss: 111356.2891\n",
            "Epoch 450/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106675.6484 - val_loss: 111332.4609\n",
            "Epoch 451/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106658.7266 - val_loss: 111308.2109\n",
            "Epoch 452/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106642.1797 - val_loss: 111288.1172\n",
            "Epoch 453/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106625.8594 - val_loss: 111274.7109\n",
            "Epoch 454/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106606.9062 - val_loss: 111246.3984\n",
            "Epoch 455/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 106590.5781 - val_loss: 111236.0547\n",
            "Epoch 456/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 106574.6172 - val_loss: 111205.3516\n",
            "Epoch 457/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106556.3203 - val_loss: 111182.4375\n",
            "Epoch 458/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106544.6172 - val_loss: 111162.2422\n",
            "Epoch 459/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106526.3672 - val_loss: 111142.5156\n",
            "Epoch 460/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106506.3438 - val_loss: 111125.2734\n",
            "Epoch 461/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106489.2188 - val_loss: 111104.7969\n",
            "Epoch 462/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 106468.5938 - val_loss: 111086.8828\n",
            "Epoch 463/500\n",
            "130/130 [==============================] - 0s 4ms/step - loss: 106449.3906 - val_loss: 111070.5078\n",
            "Epoch 464/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106438.4375 - val_loss: 111051.0234\n",
            "Epoch 465/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106420.2891 - val_loss: 111025.9531\n",
            "Epoch 466/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106402.6797 - val_loss: 111004.5625\n",
            "Epoch 467/500\n",
            "130/130 [==============================] - 1s 5ms/step - loss: 106381.2656 - val_loss: 110981.0938\n",
            "Epoch 468/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106366.1562 - val_loss: 110964.2422\n",
            "Epoch 469/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106348.7969 - val_loss: 110941.9844\n",
            "Epoch 470/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106331.8125 - val_loss: 110914.1250\n",
            "Epoch 471/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106313.6953 - val_loss: 110898.8828\n",
            "Epoch 472/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106292.9922 - val_loss: 110889.1094\n",
            "Epoch 473/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 106278.4766 - val_loss: 110871.4453\n",
            "Epoch 474/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106261.5312 - val_loss: 110843.5078\n",
            "Epoch 475/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106247.4844 - val_loss: 110829.7109\n",
            "Epoch 476/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106225.8125 - val_loss: 110811.7656\n",
            "Epoch 477/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106208.5078 - val_loss: 110790.6641\n",
            "Epoch 478/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106191.4453 - val_loss: 110771.0703\n",
            "Epoch 479/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106178.6719 - val_loss: 110746.6172\n",
            "Epoch 480/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106157.4062 - val_loss: 110731.7188\n",
            "Epoch 481/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106139.2031 - val_loss: 110709.6719\n",
            "Epoch 482/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106121.5547 - val_loss: 110684.9688\n",
            "Epoch 483/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106101.7969 - val_loss: 110674.3203\n",
            "Epoch 484/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106089.4766 - val_loss: 110660.5859\n",
            "Epoch 485/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 106070.3359 - val_loss: 110629.8516\n",
            "Epoch 486/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106052.7344 - val_loss: 110605.7656\n",
            "Epoch 487/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 106032.7109 - val_loss: 110588.9375\n",
            "Epoch 488/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 106013.1484 - val_loss: 110565.1250\n",
            "Epoch 489/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 105996.8203 - val_loss: 110549.7266\n",
            "Epoch 490/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 105980.3750 - val_loss: 110523.0859\n",
            "Epoch 491/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 105963.8906 - val_loss: 110508.1328\n",
            "Epoch 492/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 105941.9688 - val_loss: 110489.5859\n",
            "Epoch 493/500\n",
            "130/130 [==============================] - 1s 4ms/step - loss: 105923.9453 - val_loss: 110461.2344\n",
            "Epoch 494/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 105906.6172 - val_loss: 110444.5469\n",
            "Epoch 495/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 105889.5781 - val_loss: 110414.8828\n",
            "Epoch 496/500\n",
            "130/130 [==============================] - 0s 2ms/step - loss: 105871.7266 - val_loss: 110400.4531\n",
            "Epoch 497/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 105852.2422 - val_loss: 110375.0547\n",
            "Epoch 498/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 105833.4062 - val_loss: 110362.0312\n",
            "Epoch 499/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 105815.4688 - val_loss: 110328.2891\n",
            "Epoch 500/500\n",
            "130/130 [==============================] - 0s 3ms/step - loss: 105799.5078 - val_loss: 110321.4922\n",
            "169/169 [==============================] - 0s 2ms/step - loss: 106250.3750\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_log = model.fit(X_train, y_train, epochs=400, batch_size=100, validation_split=.2, verbose=1)\n",
        "model.evaluate(X_test, y_test)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3vc6DpiZVRZ"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Make a simple neural network for predicting the price of homes in California. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZqmBczcMZVRZ",
        "outputId": "da98e1e8-4f49-4a0b-ee35-34c696f10dca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.3252</td>\n",
              "      <td>41.0</td>\n",
              "      <td>6.984127</td>\n",
              "      <td>1.023810</td>\n",
              "      <td>322.0</td>\n",
              "      <td>2.555556</td>\n",
              "      <td>37.88</td>\n",
              "      <td>-122.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.3014</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6.238137</td>\n",
              "      <td>0.971880</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>2.109842</td>\n",
              "      <td>37.86</td>\n",
              "      <td>-122.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.2574</td>\n",
              "      <td>52.0</td>\n",
              "      <td>8.288136</td>\n",
              "      <td>1.073446</td>\n",
              "      <td>496.0</td>\n",
              "      <td>2.802260</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.6431</td>\n",
              "      <td>52.0</td>\n",
              "      <td>5.817352</td>\n",
              "      <td>1.073059</td>\n",
              "      <td>558.0</td>\n",
              "      <td>2.547945</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.8462</td>\n",
              "      <td>52.0</td>\n",
              "      <td>6.281853</td>\n",
              "      <td>1.081081</td>\n",
              "      <td>565.0</td>\n",
              "      <td>2.181467</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
              "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
              "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
              "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
              "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
              "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
              "\n",
              "   Longitude  \n",
              "0    -122.23  \n",
              "1    -122.22  \n",
              "2    -122.24  \n",
              "3    -122.25  \n",
              "4    -122.25  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "cal = fetch_california_housing(as_frame=True)\n",
        "Xcal = pd.DataFrame(cal.data)\n",
        "ycal = pd.DataFrame(cal.target)\n",
        "Xcal.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ycal.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8TxqgdHUZVRa",
        "outputId": "f29561ee-1d8f-4b8a-f19f-b28371799e23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(15480, 8)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_cal,  X_test_cal, y_train_cal, y_test_cal = train_test_split(Xcal, ycal)\n",
        "X_train_cal.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "k0kBmDdOZVRa",
        "outputId": "6bec0963-b4c7-424b-b2df-f9d98e110e79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization_1 (Normalizat  (None, 8)                17        \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 170\n",
            "Trainable params: 153\n",
            "Non-trainable params: 17\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cal_normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "cal_normalizer.adapt(np.array(X_train_cal))\n",
        "\n",
        "cal_model = Sequential()\n",
        "cal_model.add(cal_normalizer)\n",
        "cal_model.add(Dense(8, input_shape=(8,), activation='relu'))\n",
        "cal_model.add(Dense(8, activation='relu'))\n",
        "cal_model.add(Dense(1))\n",
        "cal_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XmCWLbNdZVRb",
        "outputId": "be1ca8d5-731f-4ff5-cc39-03ac81607ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "248/248 [==============================] - 2s 6ms/step - loss: 2.4382 - val_loss: 1.1409\n",
            "Epoch 2/100\n",
            "248/248 [==============================] - 0s 1ms/step - loss: 0.9263 - val_loss: 0.6787\n",
            "Epoch 3/100\n",
            "248/248 [==============================] - 0s 1ms/step - loss: 0.6465 - val_loss: 0.5505\n",
            "Epoch 4/100\n",
            "248/248 [==============================] - 0s 1ms/step - loss: 0.5417 - val_loss: 0.4855\n",
            "Epoch 5/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.4858 - val_loss: 0.4487\n",
            "Epoch 6/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.4521 - val_loss: 0.4221\n",
            "Epoch 7/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.4315 - val_loss: 0.4053\n",
            "Epoch 8/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.4139 - val_loss: 0.3953\n",
            "Epoch 9/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.3873\n",
            "Epoch 10/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3988 - val_loss: 0.3825\n",
            "Epoch 11/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3920 - val_loss: 0.3780\n",
            "Epoch 12/100\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.3895 - val_loss: 0.3741\n",
            "Epoch 13/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3852 - val_loss: 0.3718\n",
            "Epoch 14/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3834 - val_loss: 0.3709\n",
            "Epoch 15/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3812 - val_loss: 0.3677\n",
            "Epoch 16/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3778 - val_loss: 0.3658\n",
            "Epoch 17/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.3633\n",
            "Epoch 18/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3746 - val_loss: 0.3606\n",
            "Epoch 19/100\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.3743 - val_loss: 0.3588\n",
            "Epoch 20/100\n",
            "248/248 [==============================] - 1s 5ms/step - loss: 0.3708 - val_loss: 0.3584\n",
            "Epoch 21/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3686 - val_loss: 0.3581\n",
            "Epoch 22/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3674 - val_loss: 0.3571\n",
            "Epoch 23/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3667 - val_loss: 0.3551\n",
            "Epoch 24/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.3553\n",
            "Epoch 25/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3629 - val_loss: 0.3523\n",
            "Epoch 26/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3620 - val_loss: 0.3507\n",
            "Epoch 27/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3611 - val_loss: 0.3495\n",
            "Epoch 28/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3592 - val_loss: 0.3488\n",
            "Epoch 29/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3574 - val_loss: 0.3502\n",
            "Epoch 30/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.3493\n",
            "Epoch 31/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3553 - val_loss: 0.3464\n",
            "Epoch 32/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.3450\n",
            "Epoch 33/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3511 - val_loss: 0.3441\n",
            "Epoch 34/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3504 - val_loss: 0.3434\n",
            "Epoch 35/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3488 - val_loss: 0.3435\n",
            "Epoch 36/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3465 - val_loss: 0.3423\n",
            "Epoch 37/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.3419\n",
            "Epoch 38/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3438 - val_loss: 0.3388\n",
            "Epoch 39/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3424 - val_loss: 0.3410\n",
            "Epoch 40/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3409 - val_loss: 0.3386\n",
            "Epoch 41/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3400 - val_loss: 0.3392\n",
            "Epoch 42/100\n",
            "248/248 [==============================] - 0s 2ms/step - loss: 0.3390 - val_loss: 0.3352\n",
            "Epoch 43/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3376 - val_loss: 0.3345\n",
            "Epoch 44/100\n",
            "248/248 [==============================] - 0s 2ms/step - loss: 0.3363 - val_loss: 0.3338\n",
            "Epoch 45/100\n",
            "248/248 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 0.3326\n",
            "Epoch 46/100\n",
            "248/248 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.3319\n",
            "Epoch 47/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3320 - val_loss: 0.3311\n",
            "Epoch 48/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3312 - val_loss: 0.3306\n",
            "Epoch 49/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3307 - val_loss: 0.3292\n",
            "Epoch 50/100\n",
            "248/248 [==============================] - 1s 4ms/step - loss: 0.3303 - val_loss: 0.3292\n",
            "Epoch 51/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3287 - val_loss: 0.3282\n",
            "Epoch 52/100\n",
            "248/248 [==============================] - 0s 2ms/step - loss: 0.3274 - val_loss: 0.3268\n",
            "Epoch 53/100\n",
            "248/248 [==============================] - 0s 2ms/step - loss: 0.3272 - val_loss: 0.3316\n",
            "Epoch 54/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3285 - val_loss: 0.3328\n",
            "Epoch 55/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3263 - val_loss: 0.3274\n",
            "Epoch 56/100\n",
            "248/248 [==============================] - 0s 2ms/step - loss: 0.3253 - val_loss: 0.3258\n",
            "Epoch 57/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3252 - val_loss: 0.3250\n",
            "Epoch 58/100\n",
            "248/248 [==============================] - 0s 2ms/step - loss: 0.3228 - val_loss: 0.3230\n",
            "Epoch 59/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3222 - val_loss: 0.3240\n",
            "Epoch 60/100\n",
            "248/248 [==============================] - 0s 2ms/step - loss: 0.3240 - val_loss: 0.3237\n",
            "Epoch 61/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3234 - val_loss: 0.3216\n",
            "Epoch 62/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3208 - val_loss: 0.3218\n",
            "Epoch 63/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3199 - val_loss: 0.3209\n",
            "Epoch 64/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3200 - val_loss: 0.3207\n",
            "Epoch 65/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3186 - val_loss: 0.3209\n",
            "Epoch 66/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3185 - val_loss: 0.3222\n",
            "Epoch 67/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3182 - val_loss: 0.3196\n",
            "Epoch 68/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3178 - val_loss: 0.3195\n",
            "Epoch 69/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3174 - val_loss: 0.3181\n",
            "Epoch 70/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3166 - val_loss: 0.3194\n",
            "Epoch 71/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3170 - val_loss: 0.3170\n",
            "Epoch 72/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3163 - val_loss: 0.3169\n",
            "Epoch 73/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3166 - val_loss: 0.3191\n",
            "Epoch 74/100\n",
            "248/248 [==============================] - 0s 2ms/step - loss: 0.3148 - val_loss: 0.3169\n",
            "Epoch 75/100\n",
            "248/248 [==============================] - 0s 2ms/step - loss: 0.3141 - val_loss: 0.3172\n",
            "Epoch 76/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3153 - val_loss: 0.3194\n",
            "Epoch 77/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3152 - val_loss: 0.3192\n",
            "Epoch 78/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3151 - val_loss: 0.3172\n",
            "Epoch 79/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3145 - val_loss: 0.3151\n",
            "Epoch 80/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3142 - val_loss: 0.3150\n",
            "Epoch 81/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3132 - val_loss: 0.3147\n",
            "Epoch 82/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3128 - val_loss: 0.3148\n",
            "Epoch 83/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3120 - val_loss: 0.3137\n",
            "Epoch 84/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3119 - val_loss: 0.3131\n",
            "Epoch 85/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3112 - val_loss: 0.3138\n",
            "Epoch 86/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3130 - val_loss: 0.3146\n",
            "Epoch 87/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3120 - val_loss: 0.3122\n",
            "Epoch 88/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3124 - val_loss: 0.3138\n",
            "Epoch 89/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3111 - val_loss: 0.3137\n",
            "Epoch 90/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3102 - val_loss: 0.3136\n",
            "Epoch 91/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3111 - val_loss: 0.3145\n",
            "Epoch 92/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3097 - val_loss: 0.3136\n",
            "Epoch 93/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3108 - val_loss: 0.3129\n",
            "Epoch 94/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3094 - val_loss: 0.3125\n",
            "Epoch 95/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3093 - val_loss: 0.3139\n",
            "Epoch 96/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3109 - val_loss: 0.3136\n",
            "Epoch 97/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3099 - val_loss: 0.3139\n",
            "Epoch 98/100\n",
            "248/248 [==============================] - 1s 3ms/step - loss: 0.3090 - val_loss: 0.3134\n",
            "Epoch 99/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3090 - val_loss: 0.3114\n",
            "Epoch 100/100\n",
            "248/248 [==============================] - 1s 2ms/step - loss: 0.3087 - val_loss: 0.3120\n",
            "162/162 [==============================] - 0s 2ms/step - loss: 0.3312\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "cal_model.compile(loss='mean_squared_error', optimizer=tf.optimizers.Adam())\n",
        "cal_train_log = cal_model.fit(X_train_cal, y_train_cal, epochs=100, batch_size=50, validation_split=.2, verbose=1)\n",
        "cal_model.evaluate(X_test_cal, y_test_cal)\n",
        "plot_loss(cal_train_log)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oUfNO6HeZVRb"
      },
      "source": [
        "## Basics of Overfitting and Underfitting in Neural Networks\n",
        "\n",
        "Just like any other type of model, our primary task in trying to attain an accurate set of predictions is to balance the overfitting and underfitting. In a neural network, the ideas are the same as with standard models, however the tools and their usage can differ slightly. \n",
        "\n",
        "### Add Data\n",
        "\n",
        "Adding data to the training set is the number one way to improve accuracy. As noted above, neural networks are commonly able to acheive very high accuracy levels if provided with very large training sets. For smaller datasets, the probability of a neural network being the best model is much lower than with big data. There isn't a replacement for having large amounts of data (though there are a few tricks that we'll look at later), and modern large neural networks are (usually) the best tool that is able to take advantage of all that data. \n",
        "\n",
        "In the near future we'll look at some common pre-trained models that people/orgs such as Google have shared, most notably ones that do things like image recognition. These models are typically trained on really large datasets - often 10s of GB or more. This massive amount of training data allows these models to be more accurate than anything that we could create, but would be unrealistic for most people to train just due to the processing power and time needed. We can take them and adjust them a bit to our needs though...\n",
        "\n",
        "### Model Capacity\n",
        "\n",
        "The model capacity is the \"size\" of the model - refering to the combination of the number of neurons on each layer and the number of layers. In general the larger a feature set is, the larger a capacity we will need to be able to avoid underfitting and make accurate predictions. However, similar to a decision tree, if the model becomes too large for the data, we are likely to overfit. \n",
        "\n",
        "In big data scenarios (e.g. Google or Tesla training image recognition models) the feature sets can be massive (e.g. a 5 megapixel image is at least 15 million features) so the networks used have a very high capacity. Because there is a lot of training data, the model is able to have a huge capacity, but not overfit. These models can take FOREVER to process (e.g. weeks with the work paralellized on dedicated and fast machines) but they are able to make very accurate predictions since they get all the \"benefits\" of overfitting - predictions highly tailored to the training data; along with all the \"benefits\" of underfitting - since there is so much training data, they are still generalized enough to predict new data. There is something of an open question on if we should expand capacity by making the layers larger with more neurons, or by adding more layers. Like most things, the answer is whatever is tested to be best for the specific problem. In general though, more layers seems to be better for most problems, and the neural networks that excel at things such as image recognition tend to be deep learning networks - those with many layers. \n",
        "\n",
        "The combination of large datasets, deep networks, and fast processing allows for most of the modern AI that we see or interact with. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OZWfGHNqZVRb",
        "outputId": "1e595b6c-0e69-477e-dc67-c505ef26ba74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization_2 (Normalizat  (None, 18)               37        \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               2432      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52,134\n",
            "Trainable params: 52,097\n",
            "Non-trainable params: 37\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Test Different Model Capacities\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_train))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(Dense(128, input_dim=18, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WXjXrQEeZVRb",
        "outputId": "7d25815a-6f32-4c0d-c89b-a255ff13816f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "169/169 [==============================] - 0s 1ms/step - loss: 68702.2266\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.compile(loss='mean_absolute_error', optimizer=tf.optimizers.Adam(learning_rate=.01))\n",
        "train_log = model.fit(X_train, y_train, epochs=500, batch_size=1000, validation_split=.2, verbose=0)\n",
        "model.evaluate(X_test, y_test)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tTocTQASZVRc"
      },
      "source": [
        "### Early Stopping\n",
        "\n",
        "Early stopping is very common with neural networks, due to the common pattern mentioned above of the optimal balance of over/under fitting occuring at some point within many, potentially dozens/hundreds/thousands, of epochs. Early stopping kills the process after it detects that validation loss is going back up. \n",
        "\n",
        "We can put early stopping in place by using a Keras function called a callback, which has odd syntax, but is quite simple to use. The patience pararmeter controls how many epcohs of worsening scores are tolerated before implementing the stop. The restore_best_weights tells the model to roll back all of its weights to the optimal point - so we automatically get the best model post-training. In most cases we probabyl want to use early stopping along with a high epoch number. We can let the model train, and just tell us when it is finished. \n",
        "\n",
        "Another parameter that we may want to implement is the \"min_delta\" parameter. This controls how much the validation loss needs to improve to be considered an improvement. If the validation loss is 0.1, and the min_delta is 0.01, then the model will stop if the validation loss goes up to 0.11, but not if it goes up to 0.12. This is useful if we have a very small validation loss, and we want to make sure that we are getting a significant improvement before stopping. In situations like the above one, where the loss is flat-ish, but bumps around a little, this may help deal with that noise and make the early stopping cutoffs work more in line with expectations.\n",
        "\n",
        "<b>Note:</b> the patience parameter requires a little bit of thought, and a good value can vary a little between scenarios. We want to make sure that we are not stopping too early, if the patience is really small, we might get a situation where a local minima is reached and we stop the model as it is trying to escape it. If the patience is too large, we might not stop the model in time, as we might have many flat loss values, then one or two that are an improvement, resetting the clock and making the training process keep going far too long. We need to base it somewhat on what the model actually does - very stable loss results might mean we need a higher patience, while a model that is very volatile might need a lower patience, as we might not have long stable periods anywhere. Values between 5 and 15 or so are common, but it is a good idea to test a few different values to see what works best - if you actually work with larger examples we'll run several trials with different parameters or model configurations with samples of the full dataset. These trials will likely give us an idea of a reasonable cutoff point for patience. Many of the patience settings in examples that are in the next few workbooks are probably lower than \"ideal\", this is entirely for practicality purposes - we might be cutting off some slightly more ideal models, but we are also saving a lot of time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "b0MYLfTBZVRc"
      },
      "outputs": [],
      "source": [
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_train))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(Dense(18, input_dim=18, activation='relu'))\n",
        "model.add(Dense(18, activation='relu'))\n",
        "model.add(Dense(18, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SFlOi1yGZVRc",
        "outputId": "256f7158-b58b-48b4-d17e-877c40d84201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "169/169 [==============================] - 0s 902us/step - loss: 76596.4609\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAArZUlEQVR4nO3de5xdZZ3n+89v7b3rlqpKUrkWqZALCWYgwQAhQKMxSJ8EHW08DkqUFtpDy4gcRc9pBjKODa3NtIyvI/NytLGZYxqwaSGNOjIqYhoskR7udiAJgRBIDEXulUqlKlX7/ps/1tpVK3VLpXLZVfB9v177tfd+9npW/fauVL71rOdZq8zdERERGUxQ7gJERGR0U1CIiMiQFBQiIjIkBYWIiAxJQSEiIkNKlruAE23y5Mk+e/bsEfc/fPgw48aNO3EFnSJjtW5Q7eUwVusG1X6yvPjii/vdfcpAr73jgmL27Nm88MILI+7f3NzM8uXLT1xBp8hYrRtUezmM1bpBtZ8sZvaHwV7ToScRERmSgkJERIakoBARkSG94+YoROTdKZfL0dLSQjqdLncpgxo/fjybN28uaw1VVVU0NTWRSqWG3UdBISLvCC0tLdTV1TF79mzMrNzlDKijo4O6urqyfX13p7W1lZaWFubMmTPsfjr0JCLvCOl0mkmTJo3akBgNzIxJkyYd86hLQSEi7xgKiaMbyWekoIgczuT59q9f442DhXKXIiIyqigoIulcge88sZVt7cVylyIiY1RtbW25SzgpFBSRIBqO6c84iYgcSUER6QkKJYWIHCd35+abb2bhwoUsWrSIhx56CIDdu3ezbNkyFi9ezMKFC/nd735HoVDgz/7sz3q2veuuu8pcfX/DWh5rZtuBDqAA5N19iZk1AA8Bs4HtwCfdvS3afjVwXbT9l9z9saj9fOBeoBr4JXCTu7uZVQL3A+cDrcBV7r496nMt8J+iUv7a3e87rnc82HuMIlM5ITL2/dX/3MQrOw+d0H2edVo9t3307GFt+5Of/IT169fz0ksvsX//fi644AKWLVvGP/3TP7Fy5Uq++tWvUigU6OrqYv369bz99tts3LgRgIMHD57Quk+EYxlRXOrui919SfT8VuBxd58PPB49x8zOAlYBZwOXA39rZomoz93A9cD86HZ51H4d0Obu84C7gDujfTUAtwEXAkuB28xs4kje6NGU1gEUlRQicpyeeuopPvWpT5FIJJg2bRof+MAHeP755znvvPP4+7//e26//XY2bNhAXV0dc+fO5c033+SLX/wiv/rVr6ivry93+f0czwl3VwDLo8f3Ac3ALVH7g+6eAbaZ2VZgaTQqqXf3pwHM7H7gY8CjUZ/bo309DHzXwjVcK4F17n4g6rOOMFx+dBx1DyjQsjqRd4zh/uZ/svggx7AvueQSnnzySX7xi1/wmc98hptvvplrrrmGl156iccee4zvfe97rF27ljVr1pziioc23KBw4Ndm5sDfufs9wDR33wXg7rvMbGq07QzgmVjflqgtFz3u217q81a0r7yZtQOT4u0D9OlhZtcTjlSYNm0azc3Nw3xbvTKF8BubzmRG1L/cOjs7x2TdoNrLYazWDYPXPn78eDo6Ok59QX10dHRwwQUXsGbNGj7+8Y/T1tbGb3/7W2677Ta2bdvGzJkzWbVqFa2trTzzzDMsW7aMVCrFihUrmD59OjfccMNJfx/pdPqYvv/DDYpL3H1nFAbrzOzVIbYd6FdzH6J9pH16G8LgugdgyZIlPpLrvadzBVj3K1IVFaP2evFDGc3XuT8a1X7qjdW6YfDaN2/eXNbLY5TU1dXx6U9/mvXr1/O+970PM+Nb3/oW8+bN4/vf/z7f/e53SaVS1NbWcv/999Pe3s5nP/tZisVwaf6dd9550t9HVVUV55577rC3H1ZQuPvO6H6vmf2UcL5gj5k1RqOJRmBvtHkLMDPWvQnYGbU3DdAe79NiZklgPHAgal/ep0/zcN/csdCqJxE5Xp2dnQA94fCtb33riNevvvpqPv/5z/fr9/vf//6U1DdSR53MNrNxZlZXegysADYCjwDXRptdC/wsevwIsMrMKs1sDuGk9XPRYaoOM7somn+4pk+f0r6uBJ7w8CDfY8AKM5sYTWKviNpOuNIUhXJCRORIwxlRTAN+Gl0fJAn8o7v/ysyeB9aa2XXADuATAO6+yczWAq8AeeBGdy9dF+MGepfHPhrdAH4A/DCa+D5AuGoKdz9gZt8Ano+2+3ppYvtE04hCRGRgRw0Kd38TeO8A7a3AZYP0uQO4Y4D2F4CFA7SniYJmgNfWACd9CUCgEYWIyIB0ZnbENKIQERmQgiImMNAlAUVEjqSgiAnMNKIQEelDQRFjpkNPIiJ9KShizEyT2SJySgz1tyu2b9/OwoX91v2UjYIiJjCtehIR6et4Lgr4jhPOUSgqRMa8R2+F3RtO7D6nL4IPfXPQl2+55RZmzZrFF77wBQBuv/12zIwnn3yStrY2crkcX/3qV1m1atUxfdl0Os0NN9zACy+8QDKZ5Nvf/jaXXnopmzZt4rOf/SzZbJZisciPf/xjTjvtND75yU/S0tJCoVDga1/7GlddddVxvW1QUBxBk9kiMlKrVq3iy1/+ck9QrF27ll/96ld85Stfob6+nv3797N06VKuuuqqnuX4w/G9730PgA0bNvDqq6+yYsUKtmzZwve//31uuukmrr76arLZLIVCgV/+8pecdtpp/OIXvwCgvb39hLw3BUWMoeWxIu8IQ/zmf7Kce+657N27l507d7Jv3z4mTpxIY2MjX/nKV3jyyScJgoBdu3axZ88epk+fPuz9PvXUU3zxi18EYMGCBcyaNYstW7Zw8cUXc8cdd9DS0sLHP/5x5s+fz6JFi/iLv/gLbrnlFj7ykY/w/ve//4S8N81RxOhPUojI8bjyyit5+OGHeeihh1i1ahUPPPAA+/bt48UXX2T9+vVMnTqVdDp9TPsc7HD4pz/9aR555BGqq6tZuXIlTzzxBGeeeSYvvvgiixYtYvXq1Xz9618/EW9LI4q4IDCKOvYkIiO0atUqPve5z7F//35++9vfsnbtWqZOnUoqleI3v/kNO3bsOOZ9Llu2jAceeIAPfvCDbNmyhR07dvCe97yHN998k7lz5/KlL32JN998k5dffpkFCxbQ0NDAn/7pn1JbW8u99957Qt6XgiImMMO17klERujss8+mo6ODGTNm0NjYyNVXX81HP/pRlixZwuLFiznzzDOPeZ9f+MIX+PznP8+iRYtIJpPce++9VFZW8tBDD/EP//APpFIppk+fzl/+5V/y/PPPc/PNNxMEAalUirvvvvuEvC8FRUygE+5E5Dht2NC72mry5Mk8/fTTPc87Ojp6/ihR6W9XDGT27Nls3LgRCP/I0EAjg9WrV7N69eoj2lauXMnKlSuPp/wBaY7iCFr1JCLSl0YUMTrhTkROpQ0bNvCZz3zmiLbKykqeffbZMlU0MAVFTKBLeIiMae5+TOcolNuiRYtYv379Kf2aIzmpWIeeYjRHITJ2VVVV0draqqsrDMHdaW1tpaqq6pj6aUQRY2YU9W9MZExqamqipaWFffv2lbuUQaXT6WP+T/pEq6qqoqmp6Zj6KChiTHMUImNWKpVizpw55S5jSM3NzZx77rnlLuOY6dBTjM6jEBHpT0ERozkKEZH+FBQxunqsiEh/CooYzVGIiPSnoIjRqicRkf4UFDE6M1tEpD8FRUwwhs7oFBE5VRQUMTr0JCLSn4IiRstjRUT6U1DE6KKAIiL9KShiTCMKEZF+FBQxphGFiEg/CooYzVGIiPSnoIjRRQFFRPpTUMQEhpbHioj0oaCIMTRHISLSl4IiRqueRET6G3ZQmFnCzP7VzH4ePW8ws3Vm9np0PzG27Woz22pmr5nZylj7+Wa2IXrtOxb9FXQzqzSzh6L2Z81sdqzPtdHXeN3Mrj0h73oQOo9CRKS/YxlR3ARsjj2/FXjc3ecDj0fPMbOzgFXA2cDlwN+aWSLqczdwPTA/ul0etV8HtLn7POAu4M5oXw3AbcCFwFLgtnggnWhBoBGFiEhfwwoKM2sC/i3w/8earwDuix7fB3ws1v6gu2fcfRuwFVhqZo1Avbs/7e4O3N+nT2lfDwOXRaONlcA6dz/g7m3AOnrD5YTTiEJEpL/kMLf7r8B/AOpibdPcfReAu+8ys6lR+wzgmdh2LVFbLnrct73U561oX3kzawcmxdsH6NPDzK4nHKkwbdo0mpubh/m2jtR2IE2+UBhx/3Lq7Owck3WDai+HsVo3qPZyOGpQmNlHgL3u/qKZLR/GPge6VrcP0T7SPr0N7vcA9wAsWbLEly8fTpn9/f2bz9G1p5WR9i+n5ubmMVk3qPZyGKt1g2ovh+EceroE+BMz2w48CHzQzP4B2BMdTiK63xtt3wLMjPVvAnZG7U0DtB/Rx8ySwHjgwBD7Oil0ZraISH9HDQp3X+3uTe4+m3CS+gl3/1PgEaC0Cula4GfR40eAVdFKpjmEk9bPRYepOszsomj+4Zo+fUr7ujL6Gg48Bqwws4nRJPaKqO2kCMwonqydi4iMUcOdoxjIN4G1ZnYdsAP4BIC7bzKztcArQB640d0LUZ8bgHuBauDR6AbwA+CHZraVcCSxKtrXATP7BvB8tN3X3f3AcdQ8JDPTiEJEpI9jCgp3bwaao8etwGWDbHcHcMcA7S8ACwdoTxMFzQCvrQHWHEudI2X6m9kiIv3ozOyYcI5CUSEiEqegiNF5FCIi/SkoYgLNUYiI9KOgiDFDq55ERPpQUMRo1ZOISH8KiphAq55ERPpRUMRojkJEpD8FRYzOoxAR6U9BEaMRhYhIfwqKGM1RiIj0p6CIMYyikkJE5AgKipLD+/nGpj/m3/HP5a5ERGRUUVD0MCo8Q9Lz5S5ERGRUUVCUBOFHEejcbBGRIygoSiwBKChERPpSUJRY+FHob9yJiBxJQVESRCMKnUghInIEBUWJDj2JiAxIQVESKChERAaioCjRHIWIyIAUFCVmOKYRhYhIHwqKmKIFCgoRkT4UFDFOQqueRET6UFDEuEYUIiL9KChinECT2SIifSgoYooWkFBQiIgcQUER45YgoIhrnkJEpIeCIsajEYX+eJGISC8FRUw4me0UNaIQEemhoIhxwlVPCgoRkV4KipjSoSflhIhILwVFjFuCwDSiEBGJU1DEaEQhItKfguIImswWEelLQRFTOo9Cy2NFRHopKGJ6Dz0pKURESo4aFGZWZWbPmdlLZrbJzP4qam8ws3Vm9np0PzHWZ7WZbTWz18xsZaz9fDPbEL32HTOzqL3SzB6K2p81s9mxPtdGX+N1M7v2hL77PtwSOuFORKSP4YwoMsAH3f29wGLgcjO7CLgVeNzd5wOPR88xs7OAVcDZwOXA35pFf5Aa7gauB+ZHt8uj9uuANnefB9wF3BntqwG4DbgQWArcFg+kE80twHCNKEREYo4aFB7qjJ6mopsDVwD3Re33AR+LHl8BPOjuGXffBmwFlppZI1Dv7k97+D/x/X36lPb1MHBZNNpYCaxz9wPu3gasozdcTjxdwkNEpJ/kcDaKRgQvAvOA77n7s2Y2zd13Abj7LjObGm0+A3gm1r0lastFj/u2l/q8Fe0rb2btwKR4+wB94vVdTzhSYdq0aTQ3Nw/nbfUzL5MlQZJ/+Zd/YULV2Jq+6ezsHPH7LjfVfuqN1bpBtZfDsILC3QvAYjObAPzUzBYOsbkNtIsh2kfaJ17fPcA9AEuWLPHly5cPUd7g9q0fR9BV4KKL/4jp46tGtI9yaW5uZqTvu9xU+6k3VusG1V4Ox/Rrs7sfBJoJD//siQ4nEd3vjTZrAWbGujUBO6P2pgHaj+hjZklgPHBgiH2dHD2T2Tr2JCJSMpxVT1OikQRmVg38MfAq8AhQWoV0LfCz6PEjwKpoJdMcwknr56LDVB1mdlE0/3BNnz6lfV0JPBHNYzwGrDCzidEk9oqo7aRwCwjM+w9ZRETexYZz6KkRuC+apwiAte7+czN7GlhrZtcBO4BPALj7JjNbC7wC5IEbo0NXADcA9wLVwKPRDeAHwA/NbCvhSGJVtK8DZvYN4Plou6+7+4HjecNDiv5mdlGz2SIiPY4aFO7+MnDuAO2twGWD9LkDuGOA9heAfvMb7p4mCpoBXlsDrDlanSdC6TwKHXkSEek1tpb2nGxBoDkKEZE+FBQxbglMFwUUETmCguII0bWeyl2GiMgooqCICxK6KKCISB8KihgvrXpSToiI9FBQxOmEOxGRfhQUcdHVY4vFchciIjJ6KChiPChNZmtEISJSoqCI0wl3IiL9KCjiLEFgmqMQEYlTUMQFCQJcq55ERGIUFHGmS3iIiPSloIizBIFOuBMROYKCIq606kk5ISLSQ0ER13PCXbkLEREZPRQUcaUT7jSkEBHpoaCIC3QJDxGRvhQUcaY5ChGRvhQUcUEyWvVU7kJEREYPBUWMBaXLjCspRERKFBRxFpAwp6jLx4qI9FBQxAVJAFxBISLSQ0ERZ+HH4cV8mQsRERk9FBQxFiTCBxpRiIj0UFDElUYUXihzISIio4eCIi4aUWgyW0Skl4IipvfQk+YoRERKFBRxFgaFVj2JiPRSUMT0jCg0RyEi0kNBEafJbBGRfhQUMUEiPOGuWNAchYhIiYIiJpEMDz3lcwoKEZESBUVMIhpR5PMKChGREgVFTCoZBkVOQSEi0kNBEVMaUSgoRER6KShikkkdehIR6euoQWFmM83sN2a22cw2mdlNUXuDma0zs9ej+4mxPqvNbKuZvWZmK2Pt55vZhui175iZRe2VZvZQ1P6smc2O9bk2+hqvm9m1J/Td9xFE51EoKEREeg1nRJEH/l93/zfARcCNZnYWcCvwuLvPBx6PnhO9tgo4G7gc+Fuz6JRnuBu4Hpgf3S6P2q8D2tx9HnAXcGe0rwbgNuBCYClwWzyQTrieoNB5FCIiJUcNCnff5e6/jx53AJuBGcAVwH3RZvcBH4seXwE86O4Zd98GbAWWmlkjUO/uT7u7A/f36VPa18PAZdFoYyWwzt0PuHsbsI7ecDnxohPu8oXcSfsSIiJjTfJYNo4OCZ0LPAtMc/ddEIaJmU2NNpsBPBPr1hK15aLHfdtLfd6K9pU3s3ZgUrx9gD7xuq4nHKkwbdo0mpubj+Vt9Zi0/xUWAXv27BnxPsqls7NzzNVcotpPvbFaN6j2chh2UJhZLfBj4MvufiiaXhhw0wHafIj2kfbpbXC/B7gHYMmSJb58+fLBahva6znYCBMmjGfE+yiT5ubmMVdziWo/9cZq3aDay2FYq57MLEUYEg+4+0+i5j3R4SSi+71RewswM9a9CdgZtTcN0H5EHzNLAuOBA0Ps6+SIDj0VNEchItJjOKueDPgBsNndvx176RGgtArpWuBnsfZV0UqmOYST1s9Fh6k6zOyiaJ/X9OlT2teVwBPRPMZjwAozmxhNYq+I2k6OnjkKBYWISMlwDj1dAnwG2GBm66O2/wh8E1hrZtcBO4BPALj7JjNbC7xCuGLqRu+9HOsNwL1ANfBodIMwiH5oZlsJRxKron0dMLNvAM9H233d3Q+M7K0OQ+kv3Gl5rIhIj6MGhbs/xcBzBQCXDdLnDuCOAdpfABYO0J4mCpoBXlsDrDlanSdEtIq3oKvHioj00JnZcYGCQkSkLwVFXDSi0ByFiEgvBUVcNJldLCooRERKFBRxQRQUmswWEemhoIiLDj1pRCEi0ktBEVdaHqvJbBGRHgqKuNKZ2RpRiIj0UFDEla6GrhGFiEgPBUVcRQ0AVWTIF4plLkZEZHRQUMRV1gNQRxeZvIJCRAQUFEeqqKWIUWddZBUUIiKAguJIQUAmqKaObrI69CQiAigo+skGNdRZN5mcgkJEBBQU/WSCGuroIqvrPYmIAAqKfrKJcZrMFhGJUVD0kUvUUGcKChGREgVFH7lETTiZraAQEQEUFP3kkxpRiIjEKSj68FQ4R3GoK1vuUkRERgUFRR9WMY4KK3Dw0KFylyIiMiooKPpIVIbXe+o8dKDMlYiIjA4Kij4KyXEAdB06WN5CRERGCQVFH/koKDKdbWWuRERkdFBQ9FFIhIee8l0KChERUFD0k66aDEB1184yVyIiMjooKPrIVE4ibykmZVvKXYqIyKigoOjLEhyqmkFjYReZvC4MKCKioBhAd90sZtseDhzWSXciIgqKAeTHz2aW7WFve7rcpYiIlJ2CYgC1p51JjWXY+ubWcpciIlJ2CooBNMw+B4DO139X5kpERMpPQTEAm3UJ+5KNLN61ttyliIiUnYJiIEGCN+Z8mvcWN3Pgie9AUZccF5F3r2S5CxitZn3oJp7Y0swHn/wa/tI92FlXwMTZMHEOzF0OCX10IvLuoP/tBtHYMJ6fX3o3/+PX9/PnmWdY9OzfYcVc+GKyCqa8B6aeBTMvhGQlTJgFM5dCIlXewkVETjAFxRD+/ANn8sPKz/GpR99PJpvh0plJrmrczVm5TUzufoOKN56Al37U26FqAkxfBO4QJKDpAmh8L1SNh8paqKiDihpo3QqT5sP4GWV7byIiw3XUoDCzNcBHgL3uvjBqawAeAmYD24FPuntb9Npq4DqgAHzJ3R+L2s8H7gWqgV8CN7m7m1klcD9wPtAKXOXu26M+1wL/KSrlr939vuN+x8fAzLjm4tl8eFEjDz3/Fj/+fQt//tx0YDpwGZPHVXDptHZmTa5lcdUu5rc9xaTMDpLJFKTb4am7wAc5uztRCVMXQK47HKEUC1B/GqQPQt10aJgLk88Mt3UHHMZNhQNvQGV9OJrp2g/jJkN1A+MPboQ9U2DSPGhvCYNqwiwwg8P7IVUThlT2MGx7Ek6/CKonnpoPUkTGtOGMKO4Fvkv4n3nJrcDj7v5NM7s1en6LmZ0FrALOBk4D/tnMznT3AnA3cD3wDGFQXA48Shgqbe4+z8xWAXcCV0VhdBuwBHDgRTN7pBRIp9Lk2kpuvHQeX1h+Bvs6M7y2u6P3tqea//lyB+ncVODjADSOr2L2pHGcscCZl9zD5FSWhmSWCYk09YkslRMaqd/5L6QObSeoqIFcdGLfoZ1QMxH2vw5bHoPC8M8MPxdgfZ/GyvpwlNP+VhhGE2eHXyPTDqlxMGku1DWGAVQ9IQykYg4KufBrTz8nbP/D/wr7TlkA2c5wX9nDYZiNbwIvQqIiDKfutvDwW6YD6meEX59ohJXrhlT18N5Qxx6omaS5IJFR4Kg/he7+pJnN7tN8BbA8enwf0AzcErU/6O4ZYJuZbQWWmtl2oN7dnwYws/uBjxEGxRXA7dG+Hga+a2YGrATWufuBqM86wnCJHes5tcyMqXVVTK2r4v3zp/S0F4rO223d7DjQxb/uaGNb62G27z/Mr7d28+DhCvLFFDCuz94uBaAiGVBbmaSmIsG4iiQ1nqC2Kkn96QUag3aqKhJUVyapSSWZXNhLcXwTtYkCU7rfJKidyrj8QSqzbWze083i0ydS0/02yYZZBLnDBAfegO4DWMOnIH0oDIyZF8AZH4TtT4Ujj45dsHtjOJIBsET4n3qqGtY/ELZV1EG243g+ORg3BQ7vhdrp0TyOhSMq4Jz9+2BDR/g162eEIbT9d1DfBBNODw/nde2Hlufh9D8KR2nuYfBU1IQLDA7thH2vQu3UMCAnnB7OHQFkDkHnPpg4Kwy8g29BEEB1A+BhuE2aFwakBeHoK5EKA3D8TEhVhSPARAUkKyCf6RmhWbEQ1uHF6JBjMtw+2wX5dOkfTu/ozT18fxXjwnaRMWCkv65Nc/ddAO6+y8ymRu0zCEcMJS1RWy563Le91OetaF95M2sHJsXbB+hzBDO7nnC0wrRp02hubh7h24LOzs7j6r8oAYumAlMBkrgn6MpDR9Z7bodzTlce0nknXYBMvki6UCRTyJI+7Oxsh20F59kCZPI5ugs58kUIj9q1Rl+pAcgDtdENeBmgFGATgSYAEgaJAFIBJMxI/h6SwWUkA0iahffJcLuUQSIRtk2v30uN5WhNTafeDjO1sI9cooYay5BPVDI1v4eJxQNYEFBBliSQSdZSSZZCsprxuX1UeJYkBWpz++mqX05tbj/mRRKepW7nVoIgwIrOvurJJDIZUju3YF6krekKqtK7qTjYRm3LvQC0j1/AuFd/TTGoAKAYVJDMH6Yy20o2NZ7D42ZS0baRRKGbysx+DA+3syS5VD2V2fDP2zrW89rxyCeqWVZIw5NH7iuXrCWV7+x57hjpqqmY56nIthN4nkxFGFLmTjFIUEhU013diHkRt4CgmCNR6KaQqKYYhAskzItMOLiJTOVEuqtnUJnZR7pqOolCF/lkLeZFgmKGYlBJV00jhUQNXTVNHGhY3POXG0uO9995Oan2U+9Ej+sH+hXJh2gfaZ8jG93vAe4BWLJkiS9fvvyohQ6mubmZ4+l/suQKRbqyBbqyeQ5nChzO5DmczdOVKZAvFnlpwybOOHMBHekcXdkCxaJTdCi4ky8UyRWK5ApOtlAkly+G94Ui2bxH96VtiqQLTjZfYE9hZth2uEg2nyRbqCNXcArF0rdh6pA1D0dFIiBfLBKYkUwYySAI7zMBqUTYlqo2UglIkCRVbyQCI5mIXg8CUuYEQUAyGVCZTFBdkaAqUcSi818SyQTJZAVVZKnL7CafqqMyaVQFBVKpCjJBNTUHt5BP1ZNMGJWeJkWeZBBQm9lN0vOkyFLMZUh6jqqqKiqKaaoy+9m+r5OmWWfQnXOqK5PUBjmSXXvJjZ9BoqKaALDsYapbt4YjknGTobKOyr2vhCMoS4TzU+mDjDuwLTzU5sWwvboRMp1QyAAens9zzr+jJt1Ozf4tMG0ute0tUDsRMm3hSLAiCd27YNdLvSOacVPgY9+H+X/c87mP1n/nw6HaT72RBsUeM2uMRhONwN6ovQWYGduuCdgZtTcN0B7v02JmSWA8cCBqX96nT/MI6x3zUomA8dUB46sHXn5btf81lp/fNOBrJ1qhGIVLFDq5Qu/zeOBk8x7bphROjrvjwMGuLK2Hs7z91lucfvrp0X6dfDHcLl8oko++Vj5qzxedfPT10rki+UKefDEMr3zRyeQLdGeLpHMFzMLfNkr15XsC7sAA76oSyMSel340Tjv6B7J98JfMIBUEVCYXU10RhhhAvnAelckgbEslSATG4UKeSkuQzRepTiVIZQ0zO/KndH90XwWWA2p6n5dMmFbB+NlJplQWuLj6Lc7f9DckfnQVnHMVvO//gcnzjv6eRGJGGhSPANcC34zufxZr/0cz+zbhT9h84Dl3L5hZh5ldBDwLXAP8tz77ehq4EngiWg31GPCfzay0NGcFsHqE9coJlAiMRJCgKpU4Iftrbt7D8uULTsi+hqNQdLL5Ipl8gXSuSCIwKpIB7r1BlY+FSymkkkE4+jnUnSedK9CVK/DGa68w7z1nMb46xcHuHK2dmZ7RW6lftlAkkwvDqysbBlgiMLL53rZ8wZlcW0k2X6S+Kkl3LqxtMO4DHzpzYNv+w3Rm8hzqznGXB0yrvJm7p/yExZv+B8GGh+G8z9CQngH+Ac2TyLAMZ3nsjwh/s59sZi2EK5G+Caw1s+uAHcAnANx9k5mtBV4hPIB+Y7TiCeAGepfHPhrdAH4A/DCa+D5AuGoKdz9gZt8Ano+2+3ppYlvkeCQCO+K3++PR3LaF5e8dxqijDLqzBV5qOciPntvBJ1/+FJN8Jd+e/HMufvE+zinmoH0dzPsgLPhoz8ICkYEMZ9XTpwZ56bJBtr8DuGOA9heAhQO0p4mCZoDX1gBrjlajiPRXXZHgormTuGjuJG790AJ++PQfuOGZKWTSV/G56t/y2T3/TMOOO7An/hpmvx/mfABmXQwzzh/+MmZ5V9AidZF3gcbx1fyHyxfw7z9wBg+/2MJPn6nm79pWML5wkKtTv+HKnS/QtP0ODMcTFVj9DJi/AmoaYO6l0LQknCyXdyUFhci7yPjqFNe9bw5n5P/AwiUX8/QbrfzrjsV8cuMuutL7WRK8xgXBFhYe2sMfPfffCShC898A4DWTsTMuDS8/k+sKT6qsnQqLPhGey9KxM1zBNeF0zX28wygoRN6lJtdW8tH3nsZH33saX/vIv6GlrZtXdy9n865DPLDrEHe+3cJbbd2sTLxAo7Uyu3Mvyzauo8H/iYIlyadqqci2Y81/gyersNJy3MnvCQ9dTZgZXkYmVQ07ngkvJXPhvw9PVgwS4Vn9tdOia6HVh22tb4QnJ46b1FtosRCd/a8LbpaLgkJEMDNmNtQws6GG/+OsaVHr+RxK53h11wpe232IzQe7+emuDt7Y3UbLoTx0w+m2hz8KNjEv/zb7mUDGKvlo63NYAhr3/Z6GwmNUeJY9NfNJUmDSz788aA2eqMQK4RJlb5iLpcaF4bH7ZcDCKzZPP4fZ7UU49GOoqO09Az9RGW679xXY8SxMOgOKeVjwb8Oz4BvOCM+6b9sGrzwSnol/wXVh3+426D4YBlbn3vDM+Wln9c7T/OHp8JI2My8Mz7wvXVbGPRxV5brCwCuNoooF2PrP4WtnXdE/4IpFOLgdJswOrxBQ2lcxH14jLtcdhuwRfQrQ8kK46CBIhu8JwqsJ5DPhRUdPIgWFiAyqvirF0jkNLJ3TcER7Olegpa2LnQfT7OtYwVttXVQUHSs6D3b+X7R2ZtnfmaG1M0Mmk6a9PaBYyHKG7SRDihQFZth+GjhEvXVRTxe1+W62+XTq6eK8/VtJUaDWunmZP6EileCM/dt5z77HON0P0r6jjmpPU8GR10MrkGBX1RlM3LmZgCLVLz/U7z0VggoSxSyFdbeTT42jMtN/MWXRkuQqJ5AoZklmDwHglqCYqKRYOR4r5gky7QTF8Ovnx02nWDOFRNc+gq69mIdLm/1nN+IN87CufdB9kPcXi/j/qsSynRQb5kFlHZZIYvu2hNdRMwsDo74pvC/mwvsgCV2t4X0xH14KJ1kB7W8DHl6axhIwfSF84t7j/8b3oaAQkWNWlUowb2od86bWDbtPNl/kYHeWw5kC7s7u9jRFh85Mns5MnmLRmd2VJREYL3dlKUSnkaRzBQ52ZVkfGJlckZbde6mfMJFiPksidzj8bT+fhkKOlkIDnYUUOS+SzHcxt7idimI30+0ACYoc9Fp+U1zMkuA1lgUvU5ftZrtPo4066uhmv9eToYJFwZtMzR0kT8A+JtDutUy2dqpzGcal0+QJOEQtrV5HngSLDm1jwqFO9vt72M1FvFo8nS6quCS/kXm73uYg89jtDRhOTS7DLp/Esn0vk6VAigxv+hI6qCERBKStmlmHdpHzBFlPUCSgPkiz0c7ktHwL6WQ9s9P7SFBgZ/JC8gWnsfVtUomAXKGGD5+E77eCQkROiYpkwNS6KoiyZe6UkR0uCS+DceGwty+dSBm/SkAmv7LnagGL8k62UOi5nE1gxmkTqjicKdDenWNKrnDE9YSKHl4JoN6dxuiqAIWis7foFNyZUHQuiLW/UnSK0ZUDtm3fzjkL5jHZjJcKRfKFItmC99SZjS6v01p0gsCoSAQUY/W/XZHgcLbAhu4cRnhOUFUywduVSQ5n8jROqFJQiIgcKzOjIhmefU9leWtpbt7J8vfPLW8RIxCUuwARERndFBQiIjIkBYWIiAxJQSEiIkNSUIiIyJAUFCIiMiQFhYiIDElBISIiQ7LB/qTiWGVm+4A/HMcuJtP7l4nHkrFaN6j2chirdYNqP1lmufuUgV54xwXF8TKzF9x9SbnrOFZjtW5Q7eUwVusG1V4OOvQkIiJDUlCIiMiQFBT93VPuAkZorNYNqr0cxmrdoNpPOc1RiIjIkDSiEBGRISkoRERkSAqKiJldbmavmdlWM7u13PUcjZltN7MNZrbezF6I2hrMbJ2ZvR7dTyx3nQBmtsbM9prZxljboLWa2ero+/Cama0sT9WD1n27mb0dfe7rzezDsddGRd1RLTPN7DdmttnMNpnZTVH7qP7ch6h71H/uZlZlZs+Z2UtR7X8VtY/qz3xY3P1dfwMSwBvAXKACeAk4q9x1HaXm7cDkPm3/Bbg1enwrcGe564xqWQacB2w8Wq3AWdHnXwnMib4viVFU9+3AXwyw7aipO6qnETgvelwHbIlqHNWf+xB1j/rPHTCgNnqcAp4FLhrtn/lwbhpRhJYCW939TXfPAg8CV5S5ppG4Argvenwf8LHyldLL3Z8EDvRpHqzWK4AH3T3j7tuArYTfn1NukLoHM2rqBnD3Xe7+++hxB7AZmMEo/9yHqHswo6JuAA91Rk9T0c0Z5Z/5cCgoQjOAt2LPWxj6H+do4MCvzexFM7s+apvm7rsg/IEDppatuqMbrNax8L34v83s5ejQVOkwwqit28xmA+cS/oY7Zj73PnXDGPjczSxhZuuBvcA6dx9Tn/lgFBQhG6BttK8bvsTdzwM+BNxoZsvKXdAJMtq/F3cDZwCLgV3A/xe1j8q6zawW+DHwZXc/NNSmA7SVrf4B6h4Tn7u7F9x9MdAELDWzhUNsPqpqH4qCItQCzIw9bwJ2lqmWYXH3ndH9XuCnhEPWPWbWCBDd7y1fhUc1WK2j+nvh7nui/wyKwH+n91DBqKvbzFKE/9k+4O4/iZpH/ec+UN1j6XMHcPeDQDNwOWPgMz8aBUXoeWC+mc0xswpgFfBImWsalJmNM7O60mNgBbCRsOZro82uBX5WngqHZbBaHwFWmVmlmc0B5gPPlaG+AZV+4CP/J+HnDqOsbjMz4AfAZnf/duylUf25D1b3WPjczWyKmU2IHlcDfwy8yij/zIel3LPpo+UGfJhwhcUbwFfLXc9Rap1LuFriJWBTqV5gEvA48Hp031DuWqO6fkR4uCBH+FvUdUPVCnw1+j68BnxolNX9Q2AD8DLhD3rjaKs7quV9hIcxXgbWR7cPj/bPfYi6R/3nDpwD/GtU40bgL6P2Uf2ZD+emS3iIiMiQdOhJRESGpKAQEZEhKShERGRICgoRERmSgkJERIakoBARkSEpKEREZEj/GzpstxKnUBGvAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50, restore_best_weights=True, min_delta=1000) \n",
        "\n",
        "model.compile(loss='mean_absolute_error', optimizer=tf.optimizers.Adam(learning_rate=.01))\n",
        "train_log = model.fit(X_train, y_train, epochs=500, batch_size=100, validation_split=.2, verbose=0, callbacks=[callback])\n",
        "model.evaluate(X_test, y_test)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Early Stopping on Validation Loss\n",
        "\n",
        "More likely than stopping when the training loss starts to increase, we'll want to stop when the validation loss starts to increase. This is because the validation loss is a better indicator of how the model will perform on new data. This is also what allows us to set a high epoch number and walk away while training happens - as long as our model has \"room to grow\", or the capacity to fit the data, we can let it train until we've reached a minimum validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "114/114 [==============================] - 1s 3ms/step - loss: 73786.6094 - val_loss: 76116.2969\n",
            "Epoch 2/500\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 73760.3984 - val_loss: 76325.7422\n",
            "Epoch 3/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73623.5625 - val_loss: 76898.1406\n",
            "Epoch 4/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73624.0391 - val_loss: 76166.9531\n",
            "Epoch 5/500\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 73731.1406 - val_loss: 76280.1797\n",
            "Epoch 6/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73552.9141 - val_loss: 75836.5234\n",
            "Epoch 7/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73684.0703 - val_loss: 76608.3125\n",
            "Epoch 8/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73561.4531 - val_loss: 76775.2812\n",
            "Epoch 9/500\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 73622.8438 - val_loss: 75962.0938\n",
            "Epoch 10/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73612.3906 - val_loss: 76451.9141\n",
            "Epoch 11/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73440.9844 - val_loss: 76024.1250\n",
            "Epoch 12/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73534.5938 - val_loss: 76455.6484\n",
            "Epoch 13/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73488.4688 - val_loss: 76071.4141\n",
            "Epoch 14/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73376.4141 - val_loss: 76544.8203\n",
            "Epoch 15/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73386.8359 - val_loss: 76767.3672\n",
            "Epoch 16/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73333.2734 - val_loss: 76039.4062\n",
            "Epoch 17/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73320.3828 - val_loss: 75905.3281\n",
            "Epoch 18/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73449.5938 - val_loss: 76211.6641\n",
            "Epoch 19/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73417.5703 - val_loss: 76799.5781\n",
            "Epoch 20/500\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 73274.1328 - val_loss: 76600.1797\n",
            "Epoch 21/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73365.7188 - val_loss: 76138.5391\n",
            "Epoch 22/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73392.5938 - val_loss: 76277.2266\n",
            "Epoch 23/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73392.7969 - val_loss: 76965.4531\n",
            "Epoch 24/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73302.7188 - val_loss: 75757.0703\n",
            "Epoch 25/500\n",
            "114/114 [==============================] - 1s 6ms/step - loss: 73217.1719 - val_loss: 76340.6484\n",
            "Epoch 26/500\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 73521.1016 - val_loss: 76069.0312\n",
            "Epoch 27/500\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 73128.9844 - val_loss: 75761.9766\n",
            "Epoch 28/500\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 73161.3594 - val_loss: 76510.3203\n",
            "Epoch 29/500\n",
            "114/114 [==============================] - 1s 6ms/step - loss: 73152.4141 - val_loss: 76339.8047\n",
            "Epoch 30/500\n",
            "114/114 [==============================] - 1s 6ms/step - loss: 73239.6484 - val_loss: 76243.0234\n",
            "Epoch 31/500\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 73306.7578 - val_loss: 76579.4375\n",
            "Epoch 32/500\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 73206.6172 - val_loss: 76984.8203\n",
            "Epoch 33/500\n",
            "114/114 [==============================] - 0s 4ms/step - loss: 73309.5156 - val_loss: 76203.6094\n",
            "Epoch 34/500\n",
            "114/114 [==============================] - 1s 9ms/step - loss: 73090.7188 - val_loss: 76288.3203\n",
            "Epoch 35/500\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 72960.8906 - val_loss: 76384.6719\n",
            "Epoch 36/500\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 72972.2500 - val_loss: 76579.2578\n",
            "Epoch 37/500\n",
            "114/114 [==============================] - 1s 5ms/step - loss: 73187.9531 - val_loss: 76242.0391\n",
            "Epoch 38/500\n",
            "114/114 [==============================] - 0s 3ms/step - loss: 72987.3906 - val_loss: 76138.2656\n",
            "Epoch 39/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 72735.8438 - val_loss: 76266.7812\n",
            "Epoch 40/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73156.5547 - val_loss: 76443.6641\n",
            "Epoch 41/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 72971.7188 - val_loss: 75840.9766\n",
            "Epoch 42/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 72912.8047 - val_loss: 76390.3672\n",
            "Epoch 43/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 72955.9688 - val_loss: 75714.9375\n",
            "Epoch 44/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73011.0312 - val_loss: 76280.7891\n",
            "Epoch 45/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 72800.8047 - val_loss: 76178.5469\n",
            "Epoch 46/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 72706.1094 - val_loss: 75860.4453\n",
            "Epoch 47/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 73000.7422 - val_loss: 76093.6406\n",
            "Epoch 48/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 72830.1562 - val_loss: 76792.5938\n",
            "Epoch 49/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 72766.4609 - val_loss: 76066.3984\n",
            "Epoch 50/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 72863.0391 - val_loss: 76003.4844\n",
            "Epoch 51/500\n",
            "114/114 [==============================] - 0s 2ms/step - loss: 72853.5312 - val_loss: 76651.1719\n",
            "169/169 [==============================] - 0s 1ms/step - loss: 76153.3359\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, min_delta=1000) \n",
        "\n",
        "model.compile(loss='mean_absolute_error', optimizer=tf.optimizers.Adam(learning_rate=.01))\n",
        "train_log = model.fit(X_train, y_train, epochs=500, batch_size=100, validation_split=.3, verbose=1, callbacks=[callback])\n",
        "model.evaluate(X_test, y_test)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXfwUFjSZVRc"
      },
      "source": [
        "### Regularization\n",
        "\n",
        "Like other linear models, we can implement regularization to help tame overfitting. \n",
        "\n",
        "We can use both L2 (Ridge) regularization that will limit growth of coefficients, and L1 (Lasso) regularization that is able to eliminate features by shrinking their coefficients to 0. The functionality is the same as we are used to, a regularization term is added to the loss, and the optimization, such as gradient descent, is then performed as normal. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cgwwVgJ6ZVRd",
        "outputId": "7c4c3e58-3c0a-42ef-b502-764d87747a75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization_4 (Normalizat  (None, 18)               37        \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 128)               2432      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,622\n",
            "Trainable params: 35,585\n",
            "Non-trainable params: 37\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Regularization\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_train))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(Dense(128, input_dim=18, activation='relu'))\n",
        "model.add(Dense(128, activation='relu', kernel_regularizer=\"l1\"))\n",
        "model.add(Dense(128, activation='relu', kernel_regularizer=\"l2\"))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bnRVShe2ZVRd",
        "outputId": "fb5bbfba-efcd-4d12-ba31-427900c8da53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "169/169 [==============================] - 0s 996us/step - loss: 67463.7891\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.compile(loss='mean_absolute_error', optimizer=tf.optimizers.Adam(learning_rate=.01))\n",
        "train_log = model.fit(X_train, y_train, epochs=100, batch_size=100, validation_split=.2, verbose=0)\n",
        "model.evaluate(X_test, y_test)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FXboQ7N2ZVRd"
      },
      "source": [
        "### Dropout\n",
        "\n",
        "Neural networks also commonly employ a technique call dropouts to prevent overfitting. This works just like the name says, every time the data is moved from one layer to another some portion of the features are randomly held out from being used. The intuitive explanation for dropout is that because individual nodes in the network cannot rely on the output of the others, each node must output features that are useful on their own. This sounds somewhat weird, but is actually effective. The number of features held out is called the dropout rate, typically between .2 and .5. \n",
        "\n",
        "An analogy can be drawn to the bootstrapping we looked at with trees - some random subset of features is selected each time, resulting in each batch getting \"a slightly different look at the data\", thus preventing overfitting. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "gUJv1QPEZVRd",
        "outputId": "b6f5125b-b396-4dfd-9cd4-95d84f9c452e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization_5 (Normalizat  (None, 18)               37        \n",
            " ion)                                                            \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 512)               9728      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 798,246\n",
            "Trainable params: 798,209\n",
            "Non-trainable params: 37\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Dropout\n",
        "#Test Different Model Capacities\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_train))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(normalizer)\n",
        "model.add(Dense(512, input_dim=18, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EUJHDMXbZVRd",
        "outputId": "aff714cd-a820-49b3-8ede-e24737a275b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "169/169 [==============================] - 1s 5ms/step - loss: 73893.9922\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.compile(loss='mean_absolute_error', optimizer=tf.optimizers.Adam(learning_rate=.01))\n",
        "train_log = model.fit(X_train, y_train, epochs=500, batch_size=100, validation_split=.2, verbose=0)\n",
        "model.evaluate(X_test, y_test)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AkcKFzNZVRd"
      },
      "source": [
        "### Predictions\n",
        "\n",
        "Once the model is trained, using it is mostly familiar to us from the sklearn stuff. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "S-jw_zjdZVRe",
        "outputId": "0a3fbf07-c78c-4bea-fa3e-652875330375"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "73893.99084445549"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds = model.predict(X_test)\n",
        "mean_absolute_error(y_test, preds)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t9YyxGjZVRe"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Use the California data from previously and try to add some regularization things."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGstyyzcZVRe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXYC8NGfZVRe"
      },
      "source": [
        "### Customized Loss\n",
        "\n",
        "Most scenarios are totally fine with a standard loss function, but what if we have something odd? What if we are playing on The Price is Right? We want to get as close as we can, without going over. We can write a loss function to mirror that!\n",
        "\n",
        "More practically, some real life scenarios have a disperse impact of different types of error. For example, if you are working for a call centre and predicting the number of agents to staff. Having slightly too many may be an error that costs a little bit of money, but not that big of a deal. Predicting too few might incur serious penalties if callers wait and you violate an SLA. Being off in one direction is bad, being off in the other direction can cause you to \"fall off of a cliff\" so to speak. In cases where the impact of the error is not uniform, custom loss functions may make sense. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GNjj1-aHZVRe"
      },
      "outputs": [],
      "source": [
        "def priceIsRight(y_true, y_pred):\n",
        "    if y_pred <= y_true:\n",
        "        return (y_true - y_pred) ** 2\n",
        "    else:\n",
        "        return (y_true - y_pred) ** 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyN6IYzbZVRe"
      },
      "source": [
        "## Optional Exercise\n",
        "\n",
        "Try to use the California data with a customized loss function. \n",
        "\n",
        "Note: this is a 20 way classification, so you'll probably want that many neurons on the output layer, an appropriate activation (softmax), and the y values will need to be run through np_utils.to_categorical. As well, think about the loss function, try categorical crossentropy.\n",
        "\n",
        "We'll look at activation and loss functions more next week. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAEhLMc6ZVRe"
      },
      "source": [
        "## Big Exercise - Newsgroup Classification\n",
        "\n",
        "Try to classify the newsgroup data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pCHlBNRQZVRe"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "remove = (\"headers\", \"footers\", \"quotes\")\n",
        "\n",
        "data_train = fetch_20newsgroups(\n",
        "    subset=\"train\", shuffle=True, remove=remove)\n",
        "\n",
        "data_test = fetch_20newsgroups(\n",
        "    subset=\"test\", shuffle=True, remove=remove)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1e1Iq4hZVRe",
        "outputId": "e2d62827-98eb-4a5b-87ea-e91475bd0b43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: (11314, 1971374)   Test: (7532, 1971374)\n"
          ]
        }
      ],
      "source": [
        "news_tf = TfidfVectorizer(sublinear_tf=True, ngram_range=(1,3), stop_words=\"english\", strip_accents=\"unicode\")\n",
        "X_train = news_tf.fit_transform(data_train.data)\n",
        "y_train = data_train.target\n",
        "X_test = news_tf.transform(data_test.data)\n",
        "y_test = data_test.target\n",
        "print(\"Train:\", X_train.shape, \"  Test:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "DIHW5SORZVRf"
      },
      "outputs": [],
      "source": [
        "y_test = np_utils.to_categorical(y_test)\n",
        "y_train = np_utils.to_categorical(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "86ThuxsYZVRf"
      },
      "outputs": [],
      "source": [
        "in_size = 200\n",
        "tsvd = TruncatedSVD(n_components=in_size)\n",
        "X_train = tsvd.fit_transform(X_train)\n",
        "X_test = tsvd.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7H1YvGdZVRf",
        "outputId": "309f9e45-1f30-4b0f-e64e-a15cbd2bac41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_53 (Dense)            (None, 600)               120600    \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 600)               360600    \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 600)               0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 600)               360600    \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 600)               0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 400)               240400    \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 400)               0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 400)               160400    \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 400)               0         \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 200)               80200     \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 200)               0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 200)               40200     \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 20)                4020      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,367,020\n",
            "Trainable params: 1,367,020\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(in_size*3, input_dim=in_size, activation='relu'))\n",
        "model.add(Dense(in_size*3, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(in_size*3, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(in_size*2, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(in_size*2, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(in_size, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(in_size, activation='relu'))\n",
        "model.add(Dense(20, activation=\"softmax\"))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t6JlBX_aZVRf",
        "outputId": "eee94ee4-6a24-4da5-9222-23f4a3decdc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "91/91 [==============================] - 2s 11ms/step - loss: 2.7730 - accuracy: 0.1015 - val_loss: 2.5135 - val_accuracy: 0.1436\n",
            "Epoch 2/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 2.0940 - accuracy: 0.2654 - val_loss: 1.8665 - val_accuracy: 0.3411\n",
            "Epoch 3/100\n",
            "91/91 [==============================] - 1s 10ms/step - loss: 1.5779 - accuracy: 0.4559 - val_loss: 1.4100 - val_accuracy: 0.5369\n",
            "Epoch 4/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 1.2894 - accuracy: 0.5760 - val_loss: 1.2725 - val_accuracy: 0.6019\n",
            "Epoch 5/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 1.1379 - accuracy: 0.6346 - val_loss: 1.2396 - val_accuracy: 0.6178\n",
            "Epoch 6/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 1.0170 - accuracy: 0.6742 - val_loss: 1.2824 - val_accuracy: 0.6160\n",
            "Epoch 7/100\n",
            "91/91 [==============================] - 1s 10ms/step - loss: 0.9123 - accuracy: 0.7062 - val_loss: 1.2385 - val_accuracy: 0.6407\n",
            "Epoch 8/100\n",
            "91/91 [==============================] - 1s 10ms/step - loss: 0.8327 - accuracy: 0.7373 - val_loss: 1.2973 - val_accuracy: 0.6341\n",
            "Epoch 9/100\n",
            "91/91 [==============================] - 1s 10ms/step - loss: 0.7458 - accuracy: 0.7627 - val_loss: 1.3977 - val_accuracy: 0.6222\n",
            "Epoch 10/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.7057 - accuracy: 0.7756 - val_loss: 1.3395 - val_accuracy: 0.6288\n",
            "Epoch 11/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.6491 - accuracy: 0.7963 - val_loss: 1.4084 - val_accuracy: 0.6558\n",
            "Epoch 12/100\n",
            "91/91 [==============================] - 1s 10ms/step - loss: 0.5687 - accuracy: 0.8197 - val_loss: 1.4971 - val_accuracy: 0.6385\n",
            "Epoch 13/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.5434 - accuracy: 0.8243 - val_loss: 1.5894 - val_accuracy: 0.6438\n",
            "Epoch 14/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.4745 - accuracy: 0.8495 - val_loss: 1.6263 - val_accuracy: 0.6452\n",
            "Epoch 15/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.4262 - accuracy: 0.8650 - val_loss: 1.7924 - val_accuracy: 0.6438\n",
            "Epoch 16/100\n",
            "91/91 [==============================] - 1s 10ms/step - loss: 0.4246 - accuracy: 0.8694 - val_loss: 1.6010 - val_accuracy: 0.6447\n",
            "Epoch 17/100\n",
            "91/91 [==============================] - 1s 10ms/step - loss: 0.4010 - accuracy: 0.8757 - val_loss: 1.7030 - val_accuracy: 0.6368\n",
            "Epoch 18/100\n",
            "91/91 [==============================] - 1s 10ms/step - loss: 0.3679 - accuracy: 0.8864 - val_loss: 1.6972 - val_accuracy: 0.6522\n",
            "Epoch 19/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.3792 - accuracy: 0.8832 - val_loss: 1.7306 - val_accuracy: 0.6602\n",
            "Epoch 20/100\n",
            "91/91 [==============================] - 1s 10ms/step - loss: 0.3422 - accuracy: 0.8926 - val_loss: 1.6462 - val_accuracy: 0.6593\n",
            "Epoch 21/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.3109 - accuracy: 0.9075 - val_loss: 1.8239 - val_accuracy: 0.6531\n",
            "Epoch 22/100\n",
            "91/91 [==============================] - 1s 9ms/step - loss: 0.2872 - accuracy: 0.9100 - val_loss: 2.1946 - val_accuracy: 0.6412\n",
            "236/236 [==============================] - 1s 4ms/step - loss: 1.6080 - accuracy: 0.5971\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True) \n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
        "train_log = model.fit(X_train, y_train, epochs=100, batch_size=100, validation_split=.2, verbose=1, callbacks=[callback])\n",
        "model.evaluate(X_test, y_test)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Neural Network Tuning Summary vs Reality\n",
        "\n",
        "The techniques above generally expose a pattern that we can use to make accurate models:\n",
        "<ul>\n",
        "<li> Create a model that is accurate and overfitted. (Or setup process to generate an overfitted model)\n",
        "<li> Use hyperparameter tuning-ish methods to trial several different models. \n",
        "<li> Use tools such as regularization and early stopping to \"trim\" the overfitting back. \n",
        "</ul>\n",
        "\n",
        "For the most part, for what we are doing, this will probably work fine, without forcing us to put a tonne of thought into things upfront; we can just make a massive model, then reduce it. In practice the main downside to this type of brute force approach is time, and by extension, cost. For us the datasets are mostly small enough that in an extreme case we could do something like setup a bunch of trials, let our computer train and test overnight, and wake up to a model that is pretty good. If our data was scaled up by a factor of 10,000 this becomes less practical. We would want to sample the data to make each trial run much more quickly, but we'd still be dealing with a non-trivial amount of processing time for each model that we want to try. Doing things that reduce the processing requirements of each epoch, such as feature selection, choosing a \"correctly\" sized model, or smart sets of hyperparameters to try, will reduce the amount of \"bad\" trials, and allow us to dedicate more time to \"good\" trials. This is one of the, relatively rare, scenarios that paying attention to processing time can have massive impacts on the end results. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "022_keras_tensor_sol.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('ml3950')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
