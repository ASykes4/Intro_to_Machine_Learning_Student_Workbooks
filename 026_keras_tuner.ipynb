{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Base Parameters\n",
    "# Increase processing demands if on Colab\n",
    "BASE_EPOCHS = 3\n",
    "BATCH_SIZE = 256\n",
    "BASE_PATIENCE = 5\n",
    "MIN_DELTA = .02\n",
    "MONITOR = \"val_accuracy\"\n",
    "LOGS = \"logs\"\n",
    "DIR_OUT = \"kt_out\"\n",
    "PROJECT = \"kt_basics\"\n",
    "FACTOR = 3\n",
    "VALIDATION = .2\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "  BASE_EPOCHS = 5\n",
    "  BATCH_SIZE = 64\n",
    "  BASE_PATIENCE =3\n",
    "  !pip install keras_tuner\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Input\n",
    "from keras.utils import np_utils\n",
    "import datetime\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to plot loss\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.plot(history.history['val_loss'], label='val_loss')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "\n",
    "def plot_acc(history):\n",
    "  plt.plot(history.history['accuracy'], label='accuracy')\n",
    "  plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tuner\n",
    "\n",
    "We can use the Keras Tuner to find the best hyperparameters for our model, in a similar way to how we usd a grid search to find the best hyperparameters for our scikit-learn models. The process is a little more involved, but it's still pretty straightforward. \n",
    "\n",
    "### Logs and Records\n",
    "\n",
    "All of the stuff we are looking at here relies on log and record files being saved to disk. We can save them anywhere, but it is probably a good idea to consolidate them in some organized way. We can do this by creating a new directory called `logs` in the root of our project, and putting the log results in there. One thing to watch out for is that you can sometimes get odd errors or warnings if you are looking at the log files for some other model. This is because it is expecting to find things that it has written for the model to which it belongs. This is very annoying, ask me how I know. For real applications, youd probably want to make specific folders to track these things - for our repeated trials, I have added a little datetime stamp to some file names to just ensure that they are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Metrics\n",
    "acc = keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "pre = keras.metrics.Precision(name=\"precision\")\n",
    "rec = keras.metrics.Recall(name=\"recall\")\n",
    "metric_list = [acc, pre, rec]\n",
    "\n",
    "# Callbacks\n",
    "file_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOGS+\"/tb/\"+file_time, histogram_freq=1, write_images=True, embeddings_freq=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data\n",
    "\n",
    "We will start with using the fashion dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()\n",
    "print(img_train.shape, label_train.shape, img_test.shape, label_test.shape)\n",
    "\n",
    "images = np.concatenate([img_train, img_test], axis=0)\n",
    "labels = np.concatenate([label_train, label_test], axis=0)\n",
    "print(images.shape, labels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Builder\n",
    "\n",
    "To use Keras Tuner, you need to define a model builder function. This function takes a hyperparameter dictionary as input and returns a compiled model. In plain language, the model builder function is basically a framework for creating a model, with the key difference that we set things up so that the hyperparameters that we are testing are variables in the model construction. \n",
    "\n",
    "### HP.whatever\n",
    "\n",
    "The hyperparameters that we are testing are defined using the HP.[Type_of_choice] functions. For example, HP.Choice defines a hyperparameter that can take on one of a list of values. HP.Float defines a hyperparameter that can take on any value between a minimum and maximum value. HP.Int defines a hyperparameter that can take on any integer value between a minimum and maximum value. Each thing that we want to change in the search is set up with one of these \"hp.\" functions, along with the range of values we want to test.\n",
    "\n",
    "When the hyperparameter search is called, these hyperparameters will be varied according to the search algorithm that we choose - just as a grid search would work through the various combinations of hyperparameters in the list we supply. We can build this model builder function to test almost anything we can think of - different number of neurons, different number of layers, different types of layers, different activation functions, different optimizers, different learning rates, etc... The possibilities of what we can test are really only limited by our imagination and the time it takes to run the search. Some key hp items to be aware of are:\n",
    "<ul>\n",
    "<li>HP.Choice - a hyperparameter that can take on one of a list of values</li>\n",
    "<li>HP.Float - a hyperparameter that can take on any value between a minimum and maximum value</li>\n",
    "<li>HP.Int - a hyperparameter that can take on any integer value between a minimum and maximum value</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "\n",
    "  # Tune whether to use dropout.\n",
    "  #if hp.Boolean(\"dropout\"):\n",
    "  #  model.add(layers.Dropout(rate=0.25))\n",
    "\n",
    "  # Add another layer\n",
    "  #hp_units2 = hp.Int('units2', min_value=32, max_value=512, step=32)\n",
    "  #model.add(keras.layers.Dense(units=hp_units2, activation='relu'))\n",
    "\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                #loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                loss=\"categorical_crossentropy\",\n",
    "                metrics=metric_list)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder2(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  # Layer 2\n",
    "  hp_units2 = hp.Int('units2', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units2, activation='relu'))\n",
    "  \n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertuning\n",
    "\n",
    "Our model builder is the core of the hyperparameter tuning process, using it is relatively simple. We use the model builder as an input to the type of parameter search we want to do, there are a few options offered in the keras tuner:\n",
    "<ul>\n",
    "<li> Random search - randomly selects hyperparameters from the search space and trains a model for each combination. </li>\n",
    "<li> Hyperband - a more advanced search algorithm that uses early stopping to quickly identify high-performing models. This is a good option when you have a large search space and want to run a quick search. </li>\n",
    "<li> Bayesian optimization - uses Bayesian optimization to identify high-performing hyperparameter values. </li>\n",
    "</ul>\n",
    "\n",
    "Once we've setup the search, we call the search() function in a very similar way to the fit() function. The search() function will run the search and find the best set of hyperparameters for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(hypermodel = model_builder2,\n",
    "                     objective=MONITOR,\n",
    "                     max_epochs=BASE_EPOCHS,\n",
    "                     factor=FACTOR,\n",
    "                     directory=DIR_OUT,\n",
    "                     project_name=PROJECT, \n",
    "                     overwrite=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Results\n",
    "\n",
    "We can get the results of the trial, just like in a grid seach. One note on getting the best models or parameters down below is that we can get more than one. Below we are only grabbing the best model and hyperparameters, but we could get the top 3 or however many we wanted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Results\n",
    "tuner.search(img_train, label_train, epochs=BASE_EPOCHS, validation_split=VALIDATION, callbacks=[stopping])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')}, the second is {best_hps.get('units2')}, and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Best Model\n",
    "\n",
    "Once we have the best parameters, we can train a final model. Here I'll train a model on ALL of the data, since we already know the best parameter, this is the model that we think will do the best job and will be the one we can use in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(images, labels, epochs=BASE_EPOCHS, validation_split=VALIDATION)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "We can use this tuning approach to get a good fitting model without as much manual work in running trials. We can also likely repurpose parts of the model builder code, since things like testing layer sizes, number of layers, or activation functions are likely to be useful in other models and are exactly the same, no matter the specific model. \n",
    "\n",
    "The primary downside to running a search like this is that it is computationally expensive and potentially very slow to execute. When applying this to larger datasets we likely want to:\n",
    "<ul>\n",
    "<li> Use a GPU/cloud to speed up the training process. </li>\n",
    "<li> Use a sample of the data to speed up the process, or use a sample to find which types of hyperparameter choices are worthy of a larger test.</li>\n",
    "<li> Reduce number of epochs. </li>\n",
    "<li> Start with larger jumps, then narrow down on what is working. </li>\n",
    "</ul>\n",
    "\n",
    "The idea of the Keras tuning process is pretty simple, and the same as the grid search - we want to find the optimal set of hyperparameters and layer configuration for the model. The Keras Tuner makes this process much easier, and allows us to test a much larger number of combinations than we could manually, however we are much more likely to hit a limit of how many trials we can run due to time, so starting with an educated guess is still beneficial. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Larger Example\n",
    "\n",
    "We can make our model even more complex and flexible. As long as we are able to define the options with ifs and loops, we can probably try almost anything we can think of. We can try a CNN version here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: the class names are taken from the documentation\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "y_train = np_utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model4(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 4)):\n",
    "        model.add(layers.Conv2D(hp.Int(\"kernel_L\"+str(i), min_value=32, max_value=128, step=16), (3, 3), activation='relu', input_shape=(32, 32, 3), padding=\"same\"))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tuner3 = kt.RandomSearch(build_model4,\n",
    "#                        objective=MONITOR,\n",
    "#                        max_trials=5,\n",
    "#                        directory=DIR_OUT,\n",
    "#                        project_name=PROJECT,\n",
    "#                        overwrite=True)\n",
    "file_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tuner3 = kt.BayesianOptimization(build_model4,\n",
    "                        objective=MONITOR,\n",
    "                        max_trials=5,\n",
    "                        directory=DIR_OUT+\"/\"+file_time,\n",
    "                        project_name=PROJECT,\n",
    "                        overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Search\n",
    "tuner3.search(X_train, y_train, epochs=BASE_EPOCHS, validation_split=VALIDATION, callbacks=[stopping, tensorboard_callback], batch_size=BATCH_SIZE)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps3 = tuner3.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model3 = tuner3.get_best_models(num_models=1)[0]\n",
    "best_model3.build(input_shape=(None, 32, 32, 3))\n",
    "best_model3.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring Training with Tensorboard\n",
    "\n",
    "We can use the tensorboard to monitor our training as we progess. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up a timestamped log directory.\n",
    "\n",
    "logdir = \"logs/tb/train_data/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "with file_writer.as_default():\n",
    "    # Don't forget to reshape.\n",
    "    imagesW = np.reshape(X_train.astype(np.uint8), (-1, 32, 32, 3))\n",
    "    tf.summary.image(\"25 training data examples\", imagesW, step=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs/tb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoints \n",
    "\n",
    "We can also use checkpoints to save the best model as we go, this is a good way to make sure we don't lose our best model if we have to stop the training process early. This is also a good way to make sure we don't have to retrain the model if we have to restart the notebook.\n",
    "\n",
    "#### Checkpoint Callback\n",
    "\n",
    "We can build the checkpoint saving process into our model training fairly easily, by putting it into a callback. This callback is a lot like the early stopping one, but instead it just saves the weights of the model whenever it sees an improvement. If the next epoch is better, we save the updated model, if it is worse, we do nothing. On subsequent runs, we can load the weights from the checkpoint and continue training if we wish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "filepath=\"logs/weights/weights-improvement-\"+file_time+\".hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Weights\n",
    "\n",
    "Only the weights are saved in the checkpoint, it is assumed we already have the model's structure. To pick up from our checkpoint, we need to:\n",
    "<ul>\n",
    "<li> Create a model that is the correct structure. </li>\n",
    "<li> Retreive the weights from the checkpoint file. </li>\n",
    "<li> Load the weights into the model. </li>\n",
    "<li> Compile the model. </li>\n",
    "</ul>\n",
    "\n",
    "This will basically make a new model, that is exactly the same as the one that existed at the point in training when we saved the checkpoint.\n",
    "\n",
    "#### Example of Checkpoint\n",
    "\n",
    "We can see how this works by training a model a little, using the checkpoint callback, then loading the weights from the checkpoint and continuing training. I'll add a few layers and turn down the learning rate, so we can expect the training process to require a decent number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheck = keras.Sequential()\n",
    "modelCheck.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3), padding=\"same\"))\n",
    "modelCheck.add(MaxPooling2D((2, 2)))\n",
    "modelCheck.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3), padding=\"same\"))\n",
    "modelCheck.add(MaxPooling2D((2, 2)))\n",
    "modelCheck.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3), padding=\"same\"))\n",
    "modelCheck.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "modelCheck.add(Flatten())\n",
    "modelCheck.add(Dense(32, activation='relu'))\n",
    "modelCheck.add(Dense(10, activation=\"softmax\"))\n",
    "modelCheck.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelCheck.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=.0001), metrics=[metric_list])\n",
    "train_logCheck = modelCheck.fit(X_train, y_train, epochs=10, batch_size=BATCH_SIZE, validation_split=.3, verbose=1, callbacks=[stopping, checkpoint])\n",
    "test_evalCheck = modelCheck.evaluate(X_test, y_test, verbose=2)\n",
    "plot_loss(train_logCheck)\n",
    "plot_acc(train_logCheck)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution View\n",
    "\n",
    "We can break down what is happening within the model a little more here as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [layer.name for layer in modelCheck.layers]\n",
    "layer_outputs = [layer.output for layer in modelCheck.layers]\n",
    "feature_map_model = keras.models.Model(inputs=modelCheck.input, outputs=layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = X_train[1].reshape(1,32,32,3)\n",
    "#tmp = X_train[1]\n",
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_maps = feature_map_model.predict(tmp)\n",
    "#feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name, feature_map in zip(layer_names, feature_maps):\n",
    "    print(f\"The shape of the {layer_name} is =======>> {feature_map.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name, feature_map in zip(layer_names, feature_maps):\n",
    "    if len(feature_map.shape) == 4\n",
    "        k = feature_map.shape[-1]  \n",
    "        feature_image = feature_map[0, :, :, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convImg = []\n",
    "for layer_name, feature_map in zip(layer_names, feature_maps):  \n",
    "    if len(feature_map.shape) == 4:\n",
    "        k = feature_map.shape[-1]  \n",
    "        size=feature_map.shape[1]\n",
    "        for i in range(k):\n",
    "            feature_image = feature_map[0, :, :, i]\n",
    "            #feature_image-= feature_image.mean()\n",
    "            #feature_image/= feature_image.std ()\n",
    "            #feature_image*=  64\n",
    "            #feature_image+= 128\n",
    "            #feature_image= np.clip(x, 0, 255).astype('uint8')\n",
    "            #image_belt[:, i * size : (i + 1) * size] = feature_image \n",
    "            convImg.append((feature_image, layer_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(convImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up a timestamped log directory.\n",
    "logdir = \"logs/images/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.figure(figsize=(20,20))\n",
    "dimX = 20\n",
    "dimY = int(np.ceil(len(convImg)/dimX))\n",
    "curX = 0\n",
    "curY = 0\n",
    "\n",
    "fig, ax = plt.subplots(dimY,dimX, figsize=(60,60))\n",
    "plt.grid(False)\n",
    "plt.axis('off')\n",
    "\n",
    "for a in ax.flat:\n",
    "    a.set(xlabel=[], ylabel=[])\n",
    "\n",
    "for i in range(len(convImg)):\n",
    "    tmpImg = convImg[i][0]\n",
    "    tmplabel = convImg[i][1]\n",
    "    #plt.imshow(tmpImg, ax=ax(curY,curX)).set(title=tmplabel, xticks=[], yticks=[], xticklabels=[], yticklabels=[])\n",
    "    ax[curY, curX].imshow(tmpImg)\n",
    "    ax[curY, curX].set_title(tmplabel)\n",
    "    ax[curY,curX].set_xticks([])\n",
    "    ax[curY,curX].set_yticks([])\n",
    "    tf.summary.image(\"Training data\", tmpImg, step=0)\n",
    "    #plt.title(tmplabel)\n",
    "\n",
    "    curX+=1\n",
    "    if curX == dimX:\n",
    "        curX = 0\n",
    "        curY+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreating Checkpoint Model\n",
    "\n",
    "We can now take the partially trained model that we just saved, recreate it into a new model, and continue training - or do any other model related activities that we had in mind. For this one I'll let the epochs be larger, so it can run a bit more. This training process will be a \"new\" one, but the starting point is where we left off with the checkpoint weights, in my trials I saw the first epoch ot have an accuracy of about 25%, the last epoch of the previous training to have an accuracy slightly under 50%, and our training here should pick up at somewhere around 50% and continue to improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNew = keras.Sequential()\n",
    "modelNew.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3), padding=\"same\"))\n",
    "modelNew.add(MaxPooling2D((2, 2)))\n",
    "modelNew.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3), padding=\"same\"))\n",
    "modelNew.add(MaxPooling2D((2, 2)))\n",
    "modelNew.add(Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3), padding=\"same\"))\n",
    "modelNew.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "modelNew.add(Flatten())\n",
    "modelNew.add(Dense(32, activation='relu'))\n",
    "modelNew.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Load Weights\n",
    "#/Volumes/Storage/git_courses/semester/1222/3950/Intro_to_Machine_Learning_Student_Workbooks/logs/weights\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# There is a \"get_latest_checkpoint\" function in the keras documentation, but it doesn't work for me\n",
    "# locally. That is probably a better solution, but it appears to have some bug\n",
    "# There were a couple of post online about differences on mac/win/linux, but that's not certain. \n",
    "list_of_files = glob.glob(\"logs/weights/*.hdf5\") \n",
    "latest = max(list_of_files, key=os.path.getctime)\n",
    "print(latest)\n",
    "modelNew.load_weights(latest)\n",
    "modelNew.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=.0001), metrics=[metric_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_logNew = modelNew.fit(X_train, y_train, epochs=15, batch_size=BATCH_SIZE, validation_split=.3, verbose=1, callbacks=[stopping, checkpoint])\n",
    "train_evalNew = modelNew.evaluate(X_train, y_train)\n",
    "test_evalNew = modelNew.evaluate(X_test, y_test, verbose=2)\n",
    "plot_loss(train_logNew)\n",
    "plot_acc(train_logNew)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Notes\n",
    "\n",
    "Looks pretty decent. One important factor to note is that the checkpoint only saves the weights, so the other details of the model are not carried through. In particular the optimizer is not saved, so we need to make sure we compile the model with the same optimizer that we used to train it. This will also mean that the model is not picking up exactly where it left off from in the training process, as the optimizer is also learning during the training process, and it is being reset. In general though, we should be able to pick up roughly from where we left off. \n",
    "\n",
    "The details vary a little depending on the exact optimizer choice, but the main thing that is \"fogotten\" is the learning rate and momentum of the optimizer. The optimizer will attempt to learn \"how fast to move\" and \"how much to move\" during the training process, in an effort to make the process more efficient and make convergance quicker. This information is not kept, so the new optimizer we create will start with default values that are not tailored to the model. This isn't really an issue, but the training process will likely take a bit longer than it otherwise would have. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Implement a CNN model to classify the dataset. \n",
    "\n",
    "Try to:\n",
    "<ul>\n",
    "<li> Use a CNN model. </li>\n",
    "<li> Use a checkpoint to save the best model. </li>\n",
    "<li> Use tensorboard to monitor the training process. </li>\n",
    "<li> Use some hyperparameter tuning to find the best model. </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pretrained Models\n",
    "\n",
    "Our ability to save and recall models at will is powerful in allowing for a more managable training process, especially as the data becomes large and complex enough that training in one sitting is impractical. Loading models also leads us to another of the major benefits of using neural networks - we can load a model that has been trained elsewhere, usually with a massive training dataset and industrial level computing resources. \n",
    "\n",
    "Loading a model that was created elsewhere is not much more complex than loading one that we saved ourselves, in some ways it can even be easier, as several common models can be loaded directly from a function call, similar to an \"empty\" model or one of the built in keras or sklearn datasets.\n",
    "\n",
    "### But it was Trained on a Different Dataset????\n",
    "\n",
    "The models that we download were obviously trained on different datasets, not the ones that we actually want to use, so why bother with some premade model? One answer is that many of the tasks that we may want to do with a neural network are generic, for example there are several models that are trained to recognize common items in images or process text. A more targeted answer is that we can use the model as a starting point, and then fine tune it to our specific needs, which we will look at next time. In short, we can use the abilities of a highly trained model to extract information from images, then combine that with part of our own model that tailors the predictions to what we want.\n",
    "\n",
    "But first, we can load an external model and use it to make some predictions. There are several models that are pretrained and available to us to use. VGG16 is one developed to do image recognition, the name stands for \"Visual Geometry Group\" - a group of researchers at the University of Oxford who developed it, and ‘16’ implies that this architecture has 16 layers. The model got ~93% on the ImageNet test that we mentioned a couple of weeks ago. \n",
    "\n",
    "<b>Note:</b> this model, and some others that we can use, are not the sequential type that we are used to, they are functional, which basically means that they are more flexible and offer the ability to confgure models for more complex tasks. The impact that this has on us is that the syntx is a little different, but the ideas are the same. We can adapt the examples in the next 2 workbooks to use pretrained functional models, we don't need to delve into the details of their structure or setup to use them. \n",
    "\n",
    "![VGG16](images/vgg16.png \"VGG16\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(32, 32, 3))\n",
    "vgg = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = Flatten()(vgg.output)\n",
    "prediction = Dense(5)(x)\n",
    "\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "            optimizer=\"adam\", \n",
    "            metrics=keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"))\n",
    "\n",
    "log_dir = \"logs/fit/VGG\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "callback = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True) \n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "            epochs=BASE_EPOCHS,\n",
    "            verbose=1,\n",
    "            callbacks=[tensorboard_callback, callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3950",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
